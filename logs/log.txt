Namespace(GPU_ids='0', batch_size=128, device='cuda', epochs=200, evaluate=False, lr=0.1, momentum=0.9, output_dir='logs', pretrained=False, print_freq=50, resume='', save_every=10, seed=11, start_epoch=0, weight_decay=0.0001, workers=4)
resnet32: #params=464.2K
DataParallel(
  (module): ResNet(
    (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): LambdaLayer()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (2): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (3): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (4): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (linear): Linear(in_features=64, out_features=10, bias=True)
  )
)
CrossEntropyLoss()
Building dataset...
Start training
Epoch: [0]
epoch 0/200, train:, losses=1.5569, top1=28.4520, 0=34.0400, 1=36.8200, 2=7.6200, 3=16.8600, 4=21.0200, 5=27.4600, 6=40.8400, 7=28.0400, 8=39.2400, 9=32.5800, eval:, losses=1.2253, top1=43.0100, 0=47.0000, 1=65.8000, 2=26.9000, 3=14.1000, 4=28.4000, 5=42.5000, 6=44.0000, 7=54.8000, 8=59.9000, 9=46.7000, 21.7s 21.7s/1.2h
Epoch: [1]
epoch 1/200, train:, losses=1.1357, top1=46.6760, 0=49.8400, 1=60.4600, 2=26.8600, 3=31.8800, 4=34.1200, 5=40.1200, 6=56.7400, 7=54.9000, 8=57.1200, 9=54.7200, eval:, losses=1.1337, top1=49.9200, 0=32.8000, 1=80.5000, 2=20.4000, 3=3.9000, 4=49.8000, 5=31.1000, 6=70.6000, 7=74.0000, 8=73.1000, 9=63.0000, 21.4s 43.1s/1.2h
Epoch: [2]
epoch 2/200, train:, losses=0.9038, top1=58.3760, 0=62.3200, 1=71.5200, 2=46.2800, 3=38.3000, 4=50.4000, 5=47.7800, 6=67.4400, 7=62.1800, 8=70.8000, 9=66.7400, eval:, losses=0.9721, top1=57.2400, 0=52.9000, 1=82.2000, 2=38.0000, 3=46.2000, 4=43.0000, 5=75.6000, 6=46.4000, 7=41.3000, 8=91.8000, 9=55.0000, 20.9s 1.1m/1.2h
Epoch: [3]
epoch 3/200, train:, losses=0.7475, top1=66.0060, 0=68.9000, 1=79.8200, 2=55.0200, 3=44.9400, 4=59.1200, 5=54.6400, 6=73.3800, 7=69.0600, 8=78.1000, 9=77.0800, eval:, losses=0.8032, top1=65.5800, 0=59.9000, 1=78.2000, 2=57.2000, 3=45.9000, 4=44.1000, 5=57.2000, 6=58.2000, 7=80.5000, 8=94.3000, 9=80.3000, 20.3s 1.4m/1.2h
Epoch: [4]
epoch 4/200, train:, losses=0.6420, top1=71.0320, 0=73.9200, 1=84.5000, 2=60.4400, 3=51.6800, 4=65.8600, 5=59.3400, 6=76.9600, 7=74.9200, 8=82.3400, 9=80.3600, eval:, losses=0.7104, top1=69.3300, 0=83.4000, 1=71.8000, 2=50.3000, 3=79.2000, 4=64.2000, 5=56.9000, 6=64.6000, 7=55.1000, 8=81.3000, 9=86.5000, 21.4s 1.8m/1.2h
Epoch: [5]
epoch 5/200, train:, losses=0.5788, top1=73.9560, 0=75.9800, 1=87.0600, 2=63.8400, 3=56.3000, 4=70.0000, 5=61.8200, 6=79.1200, 7=78.5200, 8=83.8800, 9=83.0400, eval:, losses=0.6467, top1=71.6800, 0=88.4000, 1=81.7000, 2=68.0000, 3=32.8000, 4=62.9000, 5=77.5000, 6=81.6000, 7=76.5000, 8=81.2000, 9=66.2000, 20.6s 2.1m/1.2h
Epoch: [6]
epoch 6/200, train:, losses=0.5284, top1=76.3860, 0=78.9800, 1=87.9600, 2=67.5800, 3=59.0600, 4=73.3400, 5=64.3400, 6=81.3400, 7=79.2000, 8=87.0200, 9=85.0400, eval:, losses=0.6721, top1=72.5500, 0=77.3000, 1=88.8000, 2=70.8000, 3=36.9000, 4=52.4000, 5=62.5000, 6=79.5000, 7=95.2000, 8=92.5000, 9=69.6000, 20.1s 2.4m/1.2h
Epoch: [7]
epoch 7/200, train:, losses=0.4876, top1=78.3060, 0=80.3600, 1=89.0200, 2=70.6600, 3=61.2800, 4=75.6800, 5=66.9000, 6=83.2600, 7=81.9200, 8=87.2000, 9=86.7800, eval:, losses=0.5879, top1=75.0900, 0=77.6000, 1=70.9000, 2=67.2000, 3=37.2000, 4=75.1000, 5=71.5000, 6=74.4000, 7=89.0000, 8=92.2000, 9=95.8000, 20.5s 2.8m/1.2h
Epoch: [8]
epoch 8/200, train:, losses=0.4646, top1=79.3540, 0=82.0200, 1=89.3600, 2=72.3200, 3=62.8600, 4=77.5200, 5=68.2000, 6=84.0400, 7=82.6200, 8=88.0800, 9=86.5200, eval:, losses=0.5174, top1=78.0700, 0=82.0000, 1=91.6000, 2=66.3000, 3=47.1000, 4=85.6000, 5=70.5000, 6=72.3000, 7=85.0000, 8=90.1000, 9=90.2000, 21.5s 3.1m/1.2h
Epoch: [9]
epoch 9/200, train:, losses=0.4360, top1=80.5060, 0=82.8400, 1=90.9200, 2=72.6600, 3=64.9600, 4=78.9400, 5=69.0600, 6=85.0400, 7=83.5000, 8=89.1800, 9=87.9600, eval:, losses=0.5249, top1=77.3300, 0=67.0000, 1=83.0000, 2=78.4000, 3=69.5000, 4=88.6000, 5=58.0000, 6=75.5000, 7=71.3000, 8=94.1000, 9=87.9000, 21.2s 3.5m/1.2h
Epoch: [10]
epoch 10/200, train:, losses=0.4158, top1=81.4120, 0=83.4400, 1=90.9600, 2=74.9400, 3=65.7800, 4=80.0800, 5=70.1400, 6=85.8800, 7=84.5400, 8=89.8400, 9=88.5200, eval:, losses=0.4998, top1=79.0800, 0=88.7000, 1=89.3000, 2=65.7000, 3=47.9000, 4=72.0000, 5=75.2000, 6=82.2000, 7=90.7000, 8=84.6000, 9=94.5000, 24.3s 3.9m/1.2h
Epoch: [11]
epoch 11/200, train:, losses=0.3971, top1=82.3540, 0=84.6200, 1=91.7200, 2=76.2800, 3=67.0800, 4=80.9400, 5=70.9800, 6=86.9000, 7=85.5800, 8=90.0600, 9=89.3800, eval:, losses=0.5231, top1=78.1600, 0=87.4000, 1=93.1000, 2=83.9000, 3=55.7000, 4=75.3000, 5=52.0000, 6=84.6000, 7=86.9000, 8=71.8000, 9=90.9000, 21.8s 4.3m/1.2h
Epoch: [12]
epoch 12/200, train:, losses=0.3842, top1=82.7360, 0=84.3800, 1=91.8800, 2=76.5000, 3=68.3000, 4=81.7800, 5=72.0600, 6=87.6200, 7=85.2400, 8=90.2400, 9=89.3600, eval:, losses=0.4712, top1=80.2100, 0=90.2000, 1=86.4000, 2=79.1000, 3=76.9000, 4=76.7000, 5=62.0000, 6=85.5000, 7=72.9000, 8=84.6000, 9=87.8000, 21.4s 4.6m/1.2h
Epoch: [13]
epoch 13/200, train:, losses=0.3630, top1=84.0320, 0=85.9800, 1=92.3600, 2=78.6800, 3=70.2600, 4=83.3000, 5=73.7800, 6=87.9000, 7=86.7800, 8=91.3000, 9=89.9800, eval:, losses=0.4625, top1=80.0000, 0=90.8000, 1=83.6000, 2=70.3000, 3=73.2000, 4=83.8000, 5=61.7000, 6=77.9000, 7=81.1000, 8=89.5000, 9=88.1000, 19.4s 4.9m/1.2h
Epoch: [14]
epoch 14/200, train:, losses=0.3576, top1=84.1000, 0=85.7200, 1=92.2200, 2=78.3000, 3=70.9600, 4=83.9600, 5=73.7600, 6=87.6000, 7=87.1800, 8=91.2200, 9=90.0800, eval:, losses=0.4139, top1=82.0200, 0=80.8000, 1=83.4000, 2=68.9000, 3=71.7000, 4=80.8000, 5=71.1000, 6=91.7000, 7=84.4000, 8=93.2000, 9=94.2000, 21.2s 5.3m/1.2h
Epoch: [15]
epoch 15/200, train:, losses=0.3452, top1=84.5980, 0=86.5400, 1=92.4000, 2=78.5800, 3=71.3000, 4=84.0200, 5=74.8200, 6=89.0600, 7=87.5600, 8=91.6200, 9=90.0800, eval:, losses=0.4550, top1=81.1400, 0=92.6000, 1=97.2000, 2=72.7000, 3=57.7000, 4=73.5000, 5=82.5000, 6=86.7000, 7=88.4000, 8=78.4000, 9=81.7000, 21.3s 5.7m/1.2h
Epoch: [16]
epoch 16/200, train:, losses=0.3296, top1=85.3760, 0=87.2200, 1=92.8600, 2=80.7800, 3=72.6000, 4=84.5000, 5=75.0400, 6=89.2600, 7=88.2200, 8=92.6600, 9=90.6200, eval:, losses=0.4779, top1=80.3900, 0=72.4000, 1=92.2000, 2=59.8000, 3=59.3000, 4=81.4000, 5=83.1000, 6=91.4000, 7=75.0000, 8=93.9000, 9=95.4000, 20.8s 6.0m/1.2h
Epoch: [17]
epoch 17/200, train:, losses=0.3263, top1=85.3480, 0=87.5400, 1=93.0600, 2=80.7800, 3=71.8800, 4=84.8800, 5=75.4200, 6=88.6200, 7=88.1800, 8=92.0800, 9=91.0400, eval:, losses=0.4128, top1=82.4000, 0=93.1000, 1=88.5000, 2=73.9000, 3=78.8000, 4=81.9000, 5=53.4000, 6=89.0000, 7=89.5000, 8=87.7000, 9=88.2000, 20.9s 6.3m/1.2h
Epoch: [18]
epoch 18/200, train:, losses=0.3127, top1=86.0600, 0=88.0200, 1=92.8200, 2=80.8400, 3=73.6200, 4=86.3400, 5=76.9200, 6=90.2000, 7=88.4000, 8=92.0400, 9=91.4000, eval:, losses=0.4549, top1=81.3900, 0=77.5000, 1=94.7000, 2=68.4000, 3=56.1000, 4=78.5000, 5=89.8000, 6=90.1000, 7=80.2000, 8=85.1000, 9=93.5000, 22.1s 6.7m/1.2h
Epoch: [19]
epoch 19/200, train:, losses=0.3109, top1=86.1300, 0=87.8800, 1=93.3800, 2=81.9800, 3=73.6200, 4=85.3600, 5=76.5400, 6=90.5000, 7=89.0600, 8=91.6600, 9=91.3200, eval:, losses=0.3685, top1=84.3300, 0=87.6000, 1=93.3000, 2=79.8000, 3=59.5000, 4=80.4000, 5=78.0000, 6=89.5000, 7=93.2000, 8=92.5000, 9=89.5000, 20.8s 7.1m/1.2h
Epoch: [20]
epoch 20/200, train:, losses=0.2965, top1=86.8300, 0=88.3800, 1=93.8000, 2=82.8000, 3=74.5000, 4=87.1000, 5=77.0800, 6=90.3400, 7=89.5600, 8=93.1600, 9=91.5800, eval:, losses=0.4566, top1=82.1400, 0=94.4000, 1=91.0000, 2=87.1000, 3=63.0000, 4=83.3000, 5=60.9000, 6=87.1000, 7=82.8000, 8=88.8000, 9=83.0000, 21.5s 7.4m/1.2h
Epoch: [21]
epoch 21/200, train:, losses=0.2877, top1=87.3720, 0=89.5000, 1=94.2400, 2=82.8600, 3=75.6000, 4=87.1600, 5=78.2200, 6=91.0000, 7=89.2800, 8=93.7000, 9=92.1600, eval:, losses=0.3841, top1=84.1100, 0=86.6000, 1=89.4000, 2=73.1000, 3=74.3000, 4=72.9000, 5=83.2000, 6=86.2000, 7=90.1000, 8=90.6000, 9=94.7000, 20.7s 7.8m/1.2h
Epoch: [22]
epoch 22/200, train:, losses=0.2856, top1=87.3840, 0=88.9800, 1=93.9200, 2=83.2600, 3=76.1800, 4=87.7000, 5=78.0800, 6=90.6800, 7=89.8400, 8=93.0400, 9=92.1600, eval:, losses=0.3876, top1=83.9500, 0=77.6000, 1=85.4000, 2=79.0000, 3=64.1000, 4=81.3000, 5=84.8000, 6=89.4000, 7=91.4000, 8=91.9000, 9=94.6000, 22.5s 8.1m/1.2h
Epoch: [23]
epoch 23/200, train:, losses=0.2800, top1=87.6880, 0=89.4000, 1=93.9800, 2=83.6600, 3=76.6800, 4=87.5000, 5=78.8800, 6=91.1600, 7=89.6200, 8=93.5600, 9=92.4400, eval:, losses=0.4138, top1=83.2900, 0=86.3000, 1=95.7000, 2=73.9000, 3=66.8000, 4=89.8000, 5=58.0000, 6=93.7000, 7=90.2000, 8=89.2000, 9=89.3000, 22.6s 8.5m/1.2h
Epoch: [24]
epoch 24/200, train:, losses=0.2748, top1=87.7180, 0=89.6600, 1=94.1200, 2=83.7400, 3=76.0200, 4=87.4000, 5=79.0400, 6=91.0400, 7=90.6400, 8=93.2000, 9=92.3200, eval:, losses=0.4570, top1=82.0900, 0=90.7000, 1=90.3000, 2=73.5000, 3=80.9000, 4=71.9000, 5=78.0000, 6=91.0000, 7=73.5000, 8=86.0000, 9=85.1000, 22.5s 8.9m/1.2h
Epoch: [25]
epoch 25/200, train:, losses=0.2661, top1=88.2420, 0=90.1800, 1=94.0800, 2=84.3400, 3=77.8600, 4=88.2600, 5=79.8400, 6=91.8600, 7=90.4800, 8=93.3800, 9=92.1400, eval:, losses=0.3819, top1=84.4200, 0=85.6000, 1=89.5000, 2=81.7000, 3=77.6000, 4=90.2000, 5=68.6000, 6=82.7000, 7=86.7000, 8=94.7000, 9=86.9000, 20.9s 9.2m/1.2h
Epoch: [26]
epoch 26/200, train:, losses=0.2642, top1=88.2320, 0=89.5600, 1=94.2800, 2=84.1000, 3=77.6000, 4=88.5400, 5=79.7200, 6=91.7000, 7=90.7200, 8=93.6800, 9=92.4200, eval:, losses=0.3764, top1=83.8200, 0=92.5000, 1=90.6000, 2=73.3000, 3=81.6000, 4=83.7000, 5=67.7000, 6=81.9000, 7=86.5000, 8=88.3000, 9=92.1000, 21.9s 9.6m/1.2h
Epoch: [27]
epoch 27/200, train:, losses=0.2660, top1=88.1780, 0=89.9400, 1=94.4000, 2=83.9600, 3=77.4800, 4=88.4000, 5=79.7400, 6=91.4000, 7=90.3800, 8=93.3400, 9=92.7400, eval:, losses=0.4370, top1=82.2400, 0=92.1000, 1=93.3000, 2=84.1000, 3=62.7000, 4=59.7000, 5=78.6000, 6=95.5000, 7=72.7000, 8=92.2000, 9=91.5000, 20.9s 10.0m/1.2h
Epoch: [28]
epoch 28/200, train:, losses=0.2523, top1=88.7400, 0=89.5600, 1=94.3800, 2=85.2800, 3=78.3200, 4=88.9200, 5=81.0800, 6=92.4200, 7=91.0400, 8=93.7800, 9=92.6200, eval:, losses=0.4023, top1=83.4400, 0=86.4000, 1=84.2000, 2=85.9000, 3=62.8000, 4=84.3000, 5=77.4000, 6=78.8000, 7=87.9000, 8=95.0000, 9=91.7000, 22.0s 10.3m/1.2h
Epoch: [29]
epoch 29/200, train:, losses=0.2489, top1=88.9360, 0=90.3400, 1=94.4400, 2=85.3800, 3=78.5200, 4=89.2200, 5=81.1800, 6=92.1000, 7=91.4800, 8=93.6400, 9=93.0600, eval:, losses=0.4387, top1=82.4100, 0=73.5000, 1=94.4000, 2=60.5000, 3=84.1000, 4=77.9000, 5=75.8000, 6=87.9000, 7=86.0000, 8=95.5000, 9=88.5000, 20.7s 10.7m/1.2h
Epoch: [30]
epoch 30/200, train:, losses=0.2492, top1=88.8160, 0=90.3800, 1=94.6000, 2=85.6800, 3=78.8000, 4=88.9800, 5=80.6200, 6=91.9000, 7=91.2600, 8=93.4800, 9=92.4600, eval:, losses=0.4673, top1=81.8000, 0=91.5000, 1=96.8000, 2=77.9000, 3=50.1000, 4=83.9000, 5=81.7000, 6=94.5000, 7=86.4000, 8=95.1000, 9=60.1000, 20.8s 11.0m/1.2h
Epoch: [31]
epoch 31/200, train:, losses=0.2417, top1=89.1540, 0=90.5200, 1=94.9000, 2=86.1000, 3=78.1000, 4=89.4600, 5=81.9800, 6=91.7800, 7=91.6000, 8=93.9200, 9=93.1800, eval:, losses=0.4416, top1=82.3800, 0=93.0000, 1=82.9000, 2=71.4000, 3=64.2000, 4=90.6000, 5=72.9000, 6=83.1000, 7=94.7000, 8=80.7000, 9=90.3000, 20.7s 11.4m/1.2h
Epoch: [32]
epoch 32/200, train:, losses=0.2384, top1=89.3500, 0=90.5600, 1=94.9600, 2=86.0600, 3=79.2800, 4=89.7000, 5=81.6200, 6=92.1800, 7=91.7600, 8=94.1200, 9=93.2600, eval:, losses=0.4306, top1=83.6200, 0=89.0000, 1=77.2000, 2=69.8000, 3=72.0000, 4=80.9000, 5=84.7000, 6=89.4000, 7=84.1000, 8=91.7000, 9=97.4000, 21.3s 11.7m/1.2h
Epoch: [33]
epoch 33/200, train:, losses=0.2343, top1=89.6060, 0=91.1600, 1=95.3600, 2=85.7000, 3=79.5200, 4=89.5800, 5=81.9000, 6=93.1000, 7=91.9400, 8=94.2400, 9=93.5600, eval:, losses=0.3818, top1=84.5200, 0=90.0000, 1=96.1000, 2=86.9000, 3=78.2000, 4=88.3000, 5=69.7000, 6=69.2000, 7=91.7000, 8=94.8000, 9=80.3000, 21.3s 12.1m/1.2h
Epoch: [34]
epoch 34/200, train:, losses=0.2319, top1=89.6560, 0=91.2600, 1=94.9800, 2=85.7400, 3=79.7000, 4=90.0200, 5=82.0600, 6=92.9400, 7=92.1000, 8=94.2400, 9=93.5200, eval:, losses=0.4070, top1=83.8800, 0=77.2000, 1=90.3000, 2=81.0000, 3=73.0000, 4=94.0000, 5=83.7000, 6=83.5000, 7=86.7000, 8=78.2000, 9=91.2000, 21.3s 12.4m/1.2h
Epoch: [35]
epoch 35/200, train:, losses=0.2306, top1=89.8640, 0=91.2400, 1=94.9200, 2=87.2000, 3=80.0400, 4=89.5000, 5=82.9400, 6=93.0600, 7=91.7400, 8=94.4800, 9=93.5200, eval:, losses=0.3895, top1=83.7100, 0=89.1000, 1=95.0000, 2=83.4000, 3=77.3000, 4=84.0000, 5=78.2000, 6=62.9000, 7=88.0000, 8=92.8000, 9=86.4000, 21.5s 12.8m/1.2h
Epoch: [36]
epoch 36/200, train:, losses=0.2254, top1=89.9620, 0=91.6400, 1=95.1200, 2=85.8800, 3=79.9400, 4=90.7400, 5=82.1800, 6=93.3400, 7=92.0600, 8=94.8600, 9=93.8600, eval:, losses=0.4547, top1=82.5500, 0=88.7000, 1=90.9000, 2=74.9000, 3=76.3000, 4=90.8000, 5=64.3000, 6=90.1000, 7=65.6000, 8=96.9000, 9=87.0000, 21.1s 13.1m/1.2h
Epoch: [37]
epoch 37/200, train:, losses=0.2210, top1=90.0980, 0=91.5000, 1=95.6200, 2=86.6800, 3=80.2000, 4=90.6200, 5=82.6600, 6=92.9200, 7=92.1000, 8=94.9600, 9=93.7200, eval:, losses=0.3714, top1=85.0600, 0=91.8000, 1=92.5000, 2=88.8000, 3=78.0000, 4=81.0000, 5=71.1000, 6=88.1000, 7=80.4000, 8=90.2000, 9=88.7000, 20.4s 13.5m/1.2h
Epoch: [38]
epoch 38/200, train:, losses=0.2225, top1=90.1560, 0=91.6800, 1=95.2400, 2=87.1000, 3=81.2800, 4=90.2600, 5=82.8400, 6=92.9400, 7=92.5000, 8=94.1400, 9=93.5800, eval:, losses=0.4254, top1=82.9500, 0=79.7000, 1=85.8000, 2=70.7000, 3=71.2000, 4=91.3000, 5=63.4000, 6=87.5000, 7=90.5000, 8=96.4000, 9=93.0000, 19.9s 13.8m/1.2h
Epoch: [39]
epoch 39/200, train:, losses=0.2184, top1=90.2080, 0=91.2400, 1=95.0400, 2=86.8600, 3=81.1600, 4=90.5400, 5=83.3000, 6=93.0600, 7=92.5200, 8=94.6400, 9=93.7200, eval:, losses=0.4008, top1=83.2300, 0=68.3000, 1=82.9000, 2=72.7000, 3=78.9000, 4=80.8000, 5=81.6000, 6=85.6000, 7=93.0000, 8=92.4000, 9=96.1000, 21.7s 14.2m/1.2h
Epoch: [40]
epoch 40/200, train:, losses=0.2134, top1=90.4580, 0=92.1200, 1=95.3800, 2=86.6800, 3=81.3000, 4=90.8200, 5=83.4800, 6=93.6800, 7=92.0800, 8=95.0600, 9=93.9800, eval:, losses=0.4295, top1=83.4600, 0=86.2000, 1=95.9000, 2=84.1000, 3=83.1000, 4=91.4000, 5=56.7000, 6=77.3000, 7=79.6000, 8=92.3000, 9=88.0000, 21.7s 14.5m/1.2h
Epoch: [41]
epoch 41/200, train:, losses=0.2131, top1=90.4360, 0=92.0200, 1=95.4600, 2=86.9000, 3=81.4800, 4=90.3000, 5=83.1400, 6=93.3000, 7=92.5000, 8=95.0800, 9=94.1800, eval:, losses=0.3656, top1=85.0600, 0=89.0000, 1=92.4000, 2=83.3000, 3=78.1000, 4=75.1000, 5=80.5000, 6=86.5000, 7=80.4000, 8=90.7000, 9=94.6000, 21.0s 14.9m/1.2h
Epoch: [42]
epoch 42/200, train:, losses=0.2100, top1=90.7300, 0=91.7400, 1=95.5200, 2=87.6400, 3=82.8400, 4=91.0600, 5=83.8800, 6=93.3600, 7=92.8400, 8=94.4800, 9=93.9400, eval:, losses=0.3466, top1=86.2700, 0=94.1000, 1=87.6000, 2=74.3000, 3=71.1000, 4=90.1000, 5=78.1000, 6=93.4000, 7=91.8000, 8=91.9000, 9=90.3000, 21.7s 15.2m/1.2h
Epoch: [43]
epoch 43/200, train:, losses=0.2054, top1=90.9140, 0=92.4600, 1=95.8400, 2=87.4800, 3=81.9800, 4=91.0600, 5=84.1800, 6=93.5200, 7=92.9800, 8=95.4200, 9=94.2200, eval:, losses=0.4343, top1=82.9600, 0=85.7000, 1=83.2000, 2=78.5000, 3=86.6000, 4=64.9000, 5=78.6000, 6=85.7000, 7=83.7000, 8=90.6000, 9=92.1000, 20.9s 15.6m/1.2h
Epoch: [44]
epoch 44/200, train:, losses=0.2087, top1=90.6900, 0=92.0200, 1=95.3800, 2=87.8800, 3=82.1000, 4=90.8000, 5=84.0800, 6=93.2600, 7=92.4600, 8=94.7800, 9=94.1400, eval:, losses=0.3385, top1=86.6000, 0=90.6000, 1=94.4000, 2=73.0000, 3=75.1000, 4=87.6000, 5=79.0000, 6=93.0000, 7=89.1000, 8=95.2000, 9=89.0000, 22.0s 16.0m/1.2h
Epoch: [45]
epoch 45/200, train:, losses=0.2112, top1=90.5180, 0=92.0400, 1=95.5200, 2=86.9600, 3=81.1800, 4=90.4200, 5=84.2800, 6=93.8600, 7=92.1000, 8=94.9400, 9=93.8800, eval:, losses=0.3535, top1=85.4000, 0=86.0000, 1=94.0000, 2=78.6000, 3=83.1000, 4=89.2000, 5=60.5000, 6=91.6000, 7=86.6000, 8=92.3000, 9=92.1000, 21.4s 16.3m/1.2h
Epoch: [46]
epoch 46/200, train:, losses=0.2007, top1=90.9740, 0=92.4800, 1=95.8600, 2=88.3400, 3=81.8800, 4=91.5200, 5=84.1200, 6=93.6600, 7=92.7600, 8=94.5400, 9=94.5800, eval:, losses=0.3627, top1=85.5300, 0=90.6000, 1=98.9000, 2=86.1000, 3=70.9000, 4=81.2000, 5=84.3000, 6=82.1000, 7=90.3000, 8=88.1000, 9=82.8000, 21.7s 16.7m/1.2h
Epoch: [47]
epoch 47/200, train:, losses=0.2022, top1=90.8920, 0=92.4600, 1=95.5000, 2=87.4600, 3=82.0000, 4=91.1400, 5=84.3400, 6=94.1600, 7=92.9400, 8=94.9600, 9=93.9600, eval:, losses=0.3813, top1=85.0100, 0=85.2000, 1=94.5000, 2=83.8000, 3=60.8000, 4=70.0000, 5=90.0000, 6=87.4000, 7=90.8000, 8=96.3000, 9=91.3000, 22.2s 17.1m/1.2h
Epoch: [48]
epoch 48/200, train:, losses=0.2005, top1=90.9980, 0=92.1200, 1=95.2600, 2=87.8800, 3=82.9800, 4=91.4400, 5=84.8400, 6=93.2800, 7=93.1000, 8=94.8000, 9=94.2800, eval:, losses=0.5331, top1=80.9800, 0=80.4000, 1=91.6000, 2=60.6000, 3=49.0000, 4=75.9000, 5=88.7000, 6=93.8000, 7=96.3000, 8=84.4000, 9=89.1000, 21.7s 17.4m/1.2h
Epoch: [49]
epoch 49/200, train:, losses=0.1950, top1=91.2560, 0=92.1800, 1=95.7400, 2=88.0600, 3=83.3200, 4=91.2200, 5=84.9000, 6=94.1600, 7=93.1000, 8=95.4000, 9=94.4800, eval:, losses=0.4188, top1=84.6800, 0=80.7000, 1=96.3000, 2=85.6000, 3=68.5000, 4=90.7000, 5=63.2000, 6=87.2000, 7=87.5000, 8=94.8000, 9=92.3000, 20.9s 17.8m/1.2h
Epoch: [50]
epoch 50/200, train:, losses=0.1971, top1=91.2420, 0=92.6800, 1=95.9000, 2=88.1200, 3=83.5400, 4=91.0600, 5=84.1800, 6=94.1600, 7=93.2200, 8=94.7400, 9=94.8200, eval:, losses=0.3947, top1=85.1000, 0=70.4000, 1=96.6000, 2=75.8000, 3=76.3000, 4=86.5000, 5=86.9000, 6=88.9000, 7=89.4000, 8=94.3000, 9=85.9000, 20.5s 18.1m/1.2h
Epoch: [51]
epoch 51/200, train:, losses=0.1935, top1=91.2980, 0=92.5600, 1=95.6800, 2=88.5400, 3=83.2800, 4=91.6200, 5=85.0000, 6=93.5400, 7=93.3200, 8=94.9400, 9=94.5000, eval:, losses=0.4034, top1=84.6100, 0=84.8000, 1=90.3000, 2=90.1000, 3=56.8000, 4=71.9000, 5=88.6000, 6=89.2000, 7=88.3000, 8=90.2000, 9=95.9000, 21.5s 18.5m/1.2h
Epoch: [52]
epoch 52/200, train:, losses=0.1979, top1=91.0560, 0=92.1200, 1=95.6200, 2=88.1400, 3=82.5000, 4=90.8000, 5=84.5800, 6=94.1200, 7=92.7400, 8=95.1400, 9=94.8000, eval:, losses=0.3691, top1=85.6100, 0=82.9000, 1=94.9000, 2=93.4000, 3=63.0000, 4=86.2000, 5=78.7000, 6=84.2000, 7=89.9000, 8=90.4000, 9=92.5000, 21.8s 18.8m/1.2h
Epoch: [53]
epoch 53/200, train:, losses=0.1928, top1=91.2740, 0=92.4600, 1=95.6800, 2=88.2200, 3=82.9800, 4=91.4200, 5=85.1400, 6=93.9600, 7=93.4000, 8=95.0600, 9=94.4200, eval:, losses=0.4509, top1=83.1200, 0=85.0000, 1=96.2000, 2=70.4000, 3=70.1000, 4=61.4000, 5=84.2000, 6=94.2000, 7=88.1000, 8=96.7000, 9=84.9000, 20.4s 19.2m/1.2h
Epoch: [54]
epoch 54/200, train:, losses=0.1864, top1=91.6760, 0=92.8000, 1=95.9600, 2=89.4600, 3=83.5800, 4=92.3800, 5=84.9400, 6=93.9400, 7=93.6000, 8=95.5200, 9=94.5800, eval:, losses=0.4304, top1=83.4700, 0=89.8000, 1=91.3000, 2=71.6000, 3=63.2000, 4=70.0000, 5=88.9000, 6=90.5000, 7=94.1000, 8=80.4000, 9=94.9000, 21.0s 19.5m/1.2h
Epoch: [55]
epoch 55/200, train:, losses=0.1878, top1=91.4660, 0=92.3800, 1=95.8400, 2=88.7200, 3=84.5000, 4=91.8600, 5=84.8800, 6=94.1600, 7=92.7600, 8=95.3600, 9=94.2000, eval:, losses=0.4331, top1=83.6700, 0=90.3000, 1=94.3000, 2=78.7000, 3=83.0000, 4=80.1000, 5=65.2000, 6=81.5000, 7=92.8000, 8=75.6000, 9=95.2000, 20.8s 19.9m/1.2h
Epoch: [56]
epoch 56/200, train:, losses=0.1884, top1=91.5860, 0=92.9400, 1=96.0600, 2=88.5600, 3=83.4600, 4=91.4000, 5=85.6000, 6=93.9600, 7=93.5800, 8=95.2600, 9=95.0400, eval:, losses=0.3746, top1=85.3900, 0=89.6000, 1=77.1000, 2=74.8000, 3=69.5000, 4=91.7000, 5=85.0000, 6=87.5000, 7=94.0000, 8=88.0000, 9=96.7000, 20.4s 20.2m/1.2h
Epoch: [57]
epoch 57/200, train:, losses=0.1898, top1=91.6680, 0=93.0000, 1=95.6800, 2=88.9000, 3=83.6800, 4=91.7400, 5=85.5600, 6=93.9400, 7=93.5400, 8=95.5000, 9=95.1400, eval:, losses=0.3652, top1=85.4100, 0=84.2000, 1=95.5000, 2=78.6000, 3=84.7000, 4=87.1000, 5=79.8000, 6=87.5000, 7=76.0000, 8=87.3000, 9=93.4000, 20.3s 20.5m/1.2h
Epoch: [58]
epoch 58/200, train:, losses=0.1840, top1=91.6700, 0=92.5400, 1=95.8200, 2=88.6000, 3=83.8400, 4=91.7000, 5=85.7400, 6=94.6000, 7=93.9800, 8=95.1200, 9=94.7600, eval:, losses=0.4027, top1=84.1700, 0=90.4000, 1=97.2000, 2=80.7000, 3=72.8000, 4=85.3000, 5=80.4000, 6=84.4000, 7=84.6000, 8=84.1000, 9=81.8000, 20.9s 20.9m/1.2h
Epoch: [59]
epoch 59/200, train:, losses=0.1856, top1=91.7060, 0=92.5600, 1=96.1000, 2=89.3000, 3=83.9600, 4=92.4200, 5=85.3600, 6=94.0400, 7=93.3200, 8=95.2400, 9=94.7600, eval:, losses=0.3623, top1=86.0900, 0=90.0000, 1=85.3000, 2=83.0000, 3=59.5000, 4=85.6000, 5=86.4000, 6=89.9000, 7=95.1000, 8=90.9000, 9=95.2000, 21.2s 21.2m/1.2h
Epoch: [60]
epoch 60/200, train:, losses=0.1854, top1=91.6500, 0=93.3600, 1=95.9400, 2=88.3400, 3=83.7600, 4=91.8000, 5=85.4000, 6=94.3000, 7=93.2800, 8=95.3200, 9=95.0000, eval:, losses=0.3346, top1=86.8400, 0=90.3000, 1=92.7000, 2=72.5000, 3=79.7000, 4=89.6000, 5=79.3000, 6=91.9000, 7=88.7000, 8=95.0000, 9=88.7000, 21.2s 21.6m/1.2h
Epoch: [61]
epoch 61/200, train:, losses=0.1860, top1=91.5840, 0=92.6000, 1=96.2200, 2=89.1000, 3=83.2200, 4=91.4400, 5=85.6600, 6=94.3000, 7=93.3000, 8=95.4600, 9=94.5400, eval:, losses=0.3508, top1=86.0800, 0=83.5000, 1=91.1000, 2=85.5000, 3=82.7000, 4=86.3000, 5=69.9000, 6=82.9000, 7=94.1000, 8=91.5000, 9=93.3000, 22.1s 22.0m/1.2h
Epoch: [62]
epoch 62/200, train:, losses=0.1835, top1=91.7740, 0=92.8800, 1=96.3800, 2=89.3400, 3=84.4600, 4=91.6000, 5=85.1400, 6=94.0800, 7=93.8400, 8=95.2400, 9=94.7800, eval:, losses=0.3680, top1=86.3500, 0=81.5000, 1=91.2000, 2=77.5000, 3=75.7000, 4=95.4000, 5=79.7000, 6=90.0000, 7=90.6000, 8=93.4000, 9=88.5000, 20.3s 22.3m/1.2h
Epoch: [63]
epoch 63/200, train:, losses=0.1793, top1=91.9260, 0=92.8800, 1=96.4800, 2=88.7600, 3=84.6200, 4=92.3000, 5=85.3600, 6=94.5800, 7=93.2400, 8=95.9400, 9=95.1000, eval:, losses=0.3122, top1=87.2800, 0=83.9000, 1=96.6000, 2=78.7000, 3=82.6000, 4=92.9000, 5=73.8000, 6=90.6000, 7=90.6000, 8=92.3000, 9=90.8000, 20.3s 22.6m/1.2h
Epoch: [64]
epoch 64/200, train:, losses=0.1803, top1=91.8720, 0=93.1600, 1=96.1800, 2=89.1200, 3=84.3800, 4=92.2200, 5=85.8000, 6=94.4800, 7=93.4800, 8=95.4200, 9=94.4800, eval:, losses=0.3977, top1=85.2400, 0=83.7000, 1=89.8000, 2=87.9000, 3=64.0000, 4=92.9000, 5=69.0000, 6=92.0000, 7=82.4000, 8=96.4000, 9=94.3000, 21.0s 23.0m/1.2h
Epoch: [65]
epoch 65/200, train:, losses=0.1756, top1=92.0240, 0=92.6600, 1=96.0800, 2=89.9200, 3=84.9000, 4=91.4600, 5=86.3000, 6=94.6600, 7=93.8400, 8=95.6800, 9=94.7400, eval:, losses=0.3552, top1=86.0700, 0=89.0000, 1=93.2000, 2=87.7000, 3=75.1000, 4=79.6000, 5=78.8000, 6=83.1000, 7=89.0000, 8=90.1000, 9=95.1000, 20.0s 23.3m/1.2h
Epoch: [66]
epoch 66/200, train:, losses=0.1806, top1=91.7700, 0=92.9200, 1=95.5200, 2=89.3000, 3=84.1400, 4=92.1200, 5=85.6400, 6=93.8400, 7=93.6800, 8=95.3000, 9=95.2400, eval:, losses=0.3513, top1=86.2200, 0=83.8000, 1=95.9000, 2=79.7000, 3=78.8000, 4=78.7000, 5=85.4000, 6=83.5000, 7=92.0000, 8=94.4000, 9=90.0000, 20.5s 23.7m/1.2h
Epoch: [67]
epoch 67/200, train:, losses=0.1776, top1=92.0100, 0=93.2600, 1=95.8000, 2=89.5600, 3=84.9800, 4=91.5600, 5=86.2800, 6=94.6200, 7=93.6200, 8=95.4200, 9=95.0000, eval:, losses=0.3667, top1=86.0200, 0=73.4000, 1=95.5000, 2=84.6000, 3=79.7000, 4=87.0000, 5=79.3000, 6=94.6000, 7=83.6000, 8=92.9000, 9=89.6000, 21.2s 24.0m/1.2h
Epoch: [68]
epoch 68/200, train:, losses=0.1735, top1=92.1480, 0=92.8600, 1=96.4400, 2=89.3400, 3=84.8400, 4=92.7600, 5=86.2800, 6=94.3800, 7=93.8800, 8=95.7400, 9=94.9600, eval:, losses=0.3898, top1=85.2800, 0=93.0000, 1=93.8000, 2=81.8000, 3=61.8000, 4=80.2000, 5=80.9000, 6=87.8000, 7=94.5000, 8=93.2000, 9=85.8000, 21.6s 24.4m/1.2h
Epoch: [69]
epoch 69/200, train:, losses=0.1795, top1=91.8840, 0=92.9400, 1=95.9600, 2=89.7000, 3=84.5400, 4=92.0000, 5=85.8800, 6=94.3000, 7=93.7000, 8=95.3600, 9=94.4600, eval:, losses=0.3481, top1=86.5400, 0=87.1000, 1=91.2000, 2=84.1000, 3=74.8000, 4=91.4000, 5=70.2000, 6=90.7000, 7=87.3000, 8=93.0000, 9=95.6000, 20.6s 24.7m/1.2h
Epoch: [70]
epoch 70/200, train:, losses=0.1734, top1=92.0680, 0=92.6200, 1=96.1400, 2=89.5000, 3=84.5600, 4=92.8800, 5=85.9200, 6=94.5400, 7=94.3200, 8=95.3600, 9=94.8400, eval:, losses=0.3625, top1=86.2500, 0=89.4000, 1=94.3000, 2=84.7000, 3=61.3000, 4=86.9000, 5=71.7000, 6=92.8000, 7=92.8000, 8=95.3000, 9=93.3000, 21.1s 25.1m/1.2h
Epoch: [71]
epoch 71/200, train:, losses=0.1719, top1=92.5020, 0=93.3000, 1=96.2000, 2=90.3800, 3=85.4000, 4=92.4600, 5=87.2000, 6=94.4000, 7=94.2400, 8=96.1600, 9=95.2800, eval:, losses=0.3740, top1=85.1400, 0=83.7000, 1=97.1000, 2=84.6000, 3=79.8000, 4=87.0000, 5=74.0000, 6=90.0000, 7=78.8000, 8=84.9000, 9=91.5000, 22.4s 25.4m/1.2h
Epoch: [72]
epoch 72/200, train:, losses=0.1740, top1=92.1320, 0=93.1800, 1=96.2000, 2=89.5600, 3=84.6400, 4=92.0400, 5=86.4600, 6=94.5000, 7=94.2800, 8=95.7200, 9=94.7400, eval:, losses=0.3774, top1=84.8500, 0=91.5000, 1=86.3000, 2=85.5000, 3=83.0000, 4=78.4000, 5=75.5000, 6=92.7000, 7=81.8000, 8=81.0000, 9=92.8000, 21.1s 25.8m/1.2h
Epoch: [73]
epoch 73/200, train:, losses=0.1715, top1=92.2580, 0=92.9400, 1=96.7200, 2=89.4000, 3=84.9200, 4=92.8200, 5=86.8200, 6=94.1200, 7=94.1400, 8=95.9200, 9=94.7800, eval:, losses=0.3689, top1=86.1500, 0=95.0000, 1=91.8000, 2=74.9000, 3=76.5000, 4=92.8000, 5=80.4000, 6=80.4000, 7=89.6000, 8=92.5000, 9=87.6000, 20.5s 26.1m/1.2h
Epoch: [74]
epoch 74/200, train:, losses=0.1710, top1=92.4140, 0=93.4400, 1=96.4400, 2=90.3800, 3=85.2400, 4=92.1000, 5=86.2600, 6=94.7000, 7=94.5200, 8=95.8000, 9=95.2600, eval:, losses=0.4727, top1=83.3900, 0=97.4000, 1=97.8000, 2=63.0000, 3=65.5000, 4=81.7000, 5=78.3000, 6=90.1000, 7=86.7000, 8=88.2000, 9=85.2000, 20.6s 26.5m/1.2h
Epoch: [75]
epoch 75/200, train:, losses=0.1682, top1=92.4580, 0=93.7200, 1=96.2200, 2=89.5800, 3=85.3400, 4=92.5200, 5=87.4200, 6=94.8000, 7=94.2200, 8=95.8800, 9=94.8800, eval:, losses=0.3259, top1=86.6900, 0=92.3000, 1=94.0000, 2=86.3000, 3=78.3000, 4=80.0000, 5=77.6000, 6=89.6000, 7=90.8000, 8=82.1000, 9=95.9000, 21.6s 26.8m/1.2h
Epoch: [76]
epoch 76/200, train:, losses=0.1661, top1=92.5180, 0=93.6000, 1=96.0200, 2=90.3400, 3=85.7200, 4=92.6800, 5=87.3600, 6=94.3600, 7=94.2600, 8=95.9400, 9=94.9000, eval:, losses=0.4276, top1=84.8600, 0=83.7000, 1=97.2000, 2=81.9000, 3=53.7000, 4=84.3000, 5=75.2000, 6=93.8000, 7=95.0000, 8=93.4000, 9=90.4000, 21.4s 27.2m/1.2h
Epoch: [77]
epoch 77/200, train:, losses=0.1720, top1=92.3040, 0=93.4200, 1=96.3000, 2=89.7800, 3=85.8800, 4=92.4200, 5=87.2200, 6=94.0400, 7=93.9600, 8=95.2600, 9=94.7600, eval:, losses=0.3554, top1=86.8800, 0=92.3000, 1=94.6000, 2=89.7000, 3=70.0000, 4=88.2000, 5=76.0000, 6=91.3000, 7=86.2000, 8=90.6000, 9=89.9000, 21.8s 27.6m/1.2h
Epoch: [78]
epoch 78/200, train:, losses=0.1664, top1=92.6040, 0=93.9000, 1=96.3600, 2=90.6000, 3=85.2000, 4=92.9200, 5=86.9800, 6=94.8200, 7=94.3600, 8=95.9200, 9=94.9800, eval:, losses=0.4321, top1=84.4500, 0=97.0000, 1=92.0000, 2=68.0000, 3=71.3000, 4=78.8000, 5=88.0000, 6=90.3000, 7=86.7000, 8=87.0000, 9=85.4000, 21.6s 27.9m/1.2h
Epoch: [79]
epoch 79/200, train:, losses=0.1646, top1=92.6060, 0=93.5400, 1=96.5400, 2=90.1200, 3=86.2200, 4=92.4600, 5=87.0000, 6=94.8200, 7=93.9000, 8=96.3000, 9=95.1600, eval:, losses=0.3301, top1=87.8600, 0=89.8000, 1=95.4000, 2=86.1000, 3=74.9000, 4=89.4000, 5=78.7000, 6=95.2000, 7=87.6000, 8=93.0000, 9=88.5000, 21.3s 28.3m/1.2h
Epoch: [80]
epoch 80/200, train:, losses=0.1638, top1=92.6160, 0=93.4600, 1=96.3000, 2=89.6800, 3=86.1000, 4=92.8200, 5=86.8600, 6=94.8800, 7=94.5200, 8=96.3000, 9=95.2400, eval:, losses=0.3997, top1=85.2300, 0=89.2000, 1=93.8000, 2=91.3000, 3=55.3000, 4=79.8000, 5=80.0000, 6=89.5000, 7=93.1000, 8=85.4000, 9=94.9000, 21.9s 28.6m/1.2h
Epoch: [81]
epoch 81/200, train:, losses=0.1690, top1=92.4160, 0=93.5200, 1=96.5200, 2=89.8200, 3=85.5400, 4=92.6200, 5=86.3000, 6=94.6400, 7=94.0800, 8=95.9800, 9=95.1400, eval:, losses=0.3671, top1=86.2400, 0=93.7000, 1=93.4000, 2=86.4000, 3=74.4000, 4=89.7000, 5=72.7000, 6=81.0000, 7=95.1000, 8=91.4000, 9=84.6000, 20.7s 29.0m/1.2h
Epoch: [82]
epoch 82/200, train:, losses=0.1697, top1=92.3400, 0=93.5600, 1=96.2200, 2=90.1000, 3=84.8800, 4=93.0400, 5=86.4600, 6=94.1800, 7=94.1400, 8=95.7600, 9=95.0600, eval:, losses=0.3758, top1=85.5300, 0=90.3000, 1=91.6000, 2=93.5000, 3=68.6000, 4=85.2000, 5=68.3000, 6=86.8000, 7=88.2000, 8=89.6000, 9=93.2000, 21.0s 29.3m/1.2h
Epoch: [83]
epoch 83/200, train:, losses=0.1605, top1=92.7840, 0=93.3600, 1=96.5000, 2=90.4800, 3=86.3800, 4=92.7600, 5=87.5800, 6=95.0000, 7=94.6400, 8=95.9000, 9=95.2400, eval:, losses=0.3744, top1=85.7500, 0=80.2000, 1=97.3000, 2=76.5000, 3=74.5000, 4=93.8000, 5=83.7000, 6=92.1000, 7=81.3000, 8=94.9000, 9=83.2000, 21.5s 29.7m/1.2h
Epoch: [84]
epoch 84/200, train:, losses=0.1624, top1=92.7200, 0=93.2400, 1=96.2600, 2=90.7200, 3=86.4000, 4=92.8000, 5=87.1600, 6=94.9200, 7=94.8400, 8=95.8200, 9=95.0400, eval:, losses=0.3913, top1=85.4500, 0=87.8000, 1=97.7000, 2=92.5000, 3=65.8000, 4=93.0000, 5=77.9000, 6=88.6000, 7=78.6000, 8=90.4000, 9=82.2000, 21.4s 30.1m/1.2h
Epoch: [85]
epoch 85/200, train:, losses=0.1720, top1=92.2240, 0=92.9400, 1=96.1400, 2=89.7400, 3=85.6000, 4=92.5400, 5=86.7000, 6=94.6000, 7=93.7000, 8=95.3400, 9=94.9400, eval:, losses=0.3449, top1=86.6700, 0=94.2000, 1=94.2000, 2=83.3000, 3=54.2000, 4=90.0000, 5=85.7000, 6=90.5000, 7=93.3000, 8=89.7000, 9=91.6000, 22.2s 30.4m/1.2h
Epoch: [86]
epoch 86/200, train:, losses=0.1633, top1=92.6620, 0=93.3400, 1=96.2600, 2=90.2800, 3=86.3200, 4=92.6800, 5=87.5800, 6=94.9600, 7=94.3200, 8=95.5000, 9=95.3800, eval:, losses=0.3715, top1=86.3100, 0=80.5000, 1=89.3000, 2=85.7000, 3=64.5000, 4=88.3000, 5=81.2000, 6=94.2000, 7=89.8000, 8=96.7000, 9=92.9000, 21.1s 30.8m/1.2h
Epoch: [87]
epoch 87/200, train:, losses=0.1650, top1=92.6320, 0=93.3800, 1=96.5200, 2=90.4600, 3=86.1800, 4=92.3600, 5=87.2600, 6=95.0800, 7=94.2400, 8=95.7000, 9=95.1400, eval:, losses=0.3492, top1=87.2700, 0=88.3000, 1=96.2000, 2=80.9000, 3=83.0000, 4=91.0000, 5=64.0000, 6=93.8000, 7=91.8000, 8=90.7000, 9=93.0000, 21.9s 31.1m/1.2h
Epoch: [88]
epoch 88/200, train:, losses=0.1643, top1=92.5620, 0=92.9600, 1=96.3600, 2=90.5600, 3=85.3400, 4=93.5400, 5=86.8600, 6=94.5200, 7=94.5800, 8=95.6800, 9=95.2200, eval:, losses=0.3167, top1=87.6000, 0=89.5000, 1=96.0000, 2=90.9000, 3=82.1000, 4=82.6000, 5=76.1000, 6=84.8000, 7=89.9000, 8=91.2000, 9=92.9000, 23.0s 31.5m/1.2h
Epoch: [89]
epoch 89/200, train:, losses=0.1631, top1=92.7240, 0=93.7800, 1=96.1400, 2=90.6400, 3=86.1800, 4=92.4000, 5=87.4800, 6=94.7400, 7=94.5600, 8=96.0400, 9=95.2800, eval:, losses=0.3498, top1=86.7100, 0=95.5000, 1=84.3000, 2=82.6000, 3=73.7000, 4=91.7000, 5=87.0000, 6=80.8000, 7=92.0000, 8=84.9000, 9=94.6000, 21.5s 31.9m/1.2h
Epoch: [90]
epoch 90/200, train:, losses=0.1640, top1=92.6500, 0=93.1800, 1=96.1000, 2=90.7000, 3=86.4000, 4=92.8800, 5=87.6600, 6=95.1200, 7=93.9400, 8=95.4000, 9=95.1200, eval:, losses=0.3836, top1=85.8200, 0=86.9000, 1=90.9000, 2=83.5000, 3=62.7000, 4=82.6000, 5=93.2000, 6=88.6000, 7=84.8000, 8=88.2000, 9=96.8000, 21.6s 32.2m/1.2h
Epoch: [91]
epoch 91/200, train:, losses=0.1644, top1=92.5860, 0=92.9400, 1=96.2200, 2=89.9200, 3=85.5800, 4=92.7600, 5=87.3000, 6=95.0000, 7=94.8400, 8=96.3200, 9=94.9800, eval:, losses=0.3682, top1=85.8900, 0=90.8000, 1=94.4000, 2=74.8000, 3=87.9000, 4=81.3000, 5=65.8000, 6=88.9000, 7=91.5000, 8=96.7000, 9=86.8000, 22.4s 32.6m/1.2h
Epoch: [92]
epoch 92/200, train:, losses=0.1598, top1=92.8400, 0=93.5200, 1=96.6200, 2=90.3800, 3=86.7000, 4=93.0800, 5=87.2000, 6=94.9600, 7=94.6600, 8=96.2600, 9=95.0200, eval:, losses=0.3443, top1=86.9500, 0=91.3000, 1=95.6000, 2=83.6000, 3=79.9000, 4=88.7000, 5=72.7000, 6=82.9000, 7=95.0000, 8=94.7000, 9=85.1000, 21.1s 33.0m/1.2h
Epoch: [93]
epoch 93/200, train:, losses=0.1607, top1=92.8500, 0=93.7400, 1=96.4600, 2=90.6600, 3=85.9000, 4=93.2200, 5=87.7800, 6=94.9800, 7=94.3000, 8=95.9800, 9=95.4800, eval:, losses=0.5376, top1=82.3500, 0=71.9000, 1=86.4000, 2=54.5000, 3=63.1000, 4=90.2000, 5=84.8000, 6=88.1000, 7=93.0000, 8=92.9000, 9=98.6000, 20.7s 33.3m/1.2h
Epoch: [94]
epoch 94/200, train:, losses=0.1560, top1=93.0840, 0=94.4000, 1=96.4200, 2=90.7600, 3=86.7600, 4=93.4400, 5=87.9000, 6=95.2200, 7=94.6400, 8=96.0200, 9=95.2800, eval:, losses=0.3673, top1=86.0200, 0=84.9000, 1=96.1000, 2=75.6000, 3=68.3000, 4=84.9000, 5=91.3000, 6=91.5000, 7=88.1000, 8=87.7000, 9=91.8000, 21.2s 33.7m/1.2h
Epoch: [95]
epoch 95/200, train:, losses=0.1605, top1=92.7480, 0=93.7400, 1=96.2400, 2=90.2000, 3=86.5800, 4=93.0800, 5=87.3800, 6=94.7000, 7=94.7800, 8=96.0600, 9=94.7200, eval:, losses=0.4301, top1=84.3000, 0=68.5000, 1=81.5000, 2=77.1000, 3=72.0000, 4=92.5000, 5=80.7000, 6=85.8000, 7=92.5000, 8=95.0000, 9=97.4000, 23.5s 34.1m/1.2h
Epoch: [96]
epoch 96/200, train:, losses=0.1559, top1=92.8420, 0=93.2400, 1=96.5400, 2=90.5600, 3=86.7400, 4=93.1400, 5=87.7800, 6=94.9200, 7=94.4400, 8=95.9800, 9=95.0800, eval:, losses=0.3423, top1=87.5200, 0=92.4000, 1=94.1000, 2=75.1000, 3=79.7000, 4=94.4000, 5=79.2000, 6=89.3000, 7=85.3000, 8=92.7000, 9=93.0000, 21.6s 34.4m/1.2h
Epoch: [97]
epoch 97/200, train:, losses=0.1569, top1=92.9160, 0=93.4200, 1=96.8600, 2=90.6800, 3=85.7000, 4=93.4800, 5=87.6200, 6=95.1800, 7=94.4800, 8=96.4000, 9=95.3400, eval:, losses=0.3874, top1=85.8500, 0=76.6000, 1=93.6000, 2=72.8000, 3=66.5000, 4=87.1000, 5=86.7000, 6=95.7000, 7=87.5000, 8=97.0000, 9=95.0000, 21.8s 34.8m/1.2h
Epoch: [98]
epoch 98/200, train:, losses=0.1609, top1=92.7220, 0=93.9400, 1=96.7000, 2=90.5400, 3=85.2400, 4=92.7200, 5=87.6600, 6=94.8400, 7=94.7000, 8=95.7400, 9=95.1400, eval:, losses=0.3120, top1=87.3100, 0=88.7000, 1=91.6000, 2=83.8000, 3=76.7000, 4=91.9000, 5=81.9000, 6=83.6000, 7=89.0000, 8=95.4000, 9=90.5000, 22.0s 35.1m/1.2h
Epoch: [99]
epoch 99/200, train:, losses=0.1556, top1=93.0400, 0=93.8000, 1=96.5000, 2=91.1200, 3=86.9600, 4=92.9000, 5=87.8800, 6=94.9400, 7=94.8200, 8=96.1200, 9=95.3600, eval:, losses=0.3499, top1=86.5800, 0=86.5000, 1=91.9000, 2=89.1000, 3=76.4000, 4=93.3000, 5=71.1000, 6=89.1000, 7=83.6000, 8=95.3000, 9=89.5000, 21.7s 35.5m/1.2h
Epoch: [100]
epoch 100/200, train:, losses=0.0921, top1=96.0800, 0=96.8200, 1=98.1000, 2=94.4400, 3=92.3200, 4=96.1200, 5=92.5000, 6=97.5200, 7=97.3200, 8=98.0400, 9=97.6200, eval:, losses=0.2327, top1=91.0400, 0=92.9000, 1=95.3000, 2=89.1000, 3=83.3000, 4=92.5000, 5=81.9000, 6=93.9000, 7=92.4000, 8=94.2000, 9=94.9000, 21.6s 35.9m/1.2h
Epoch: [101]
epoch 101/200, train:, losses=0.0669, top1=97.2180, 0=98.1800, 1=98.9600, 2=96.3800, 3=93.9800, 4=97.2800, 5=94.3800, 6=98.3600, 7=98.1400, 8=98.5200, 9=98.0000, eval:, losses=0.2341, top1=91.2700, 0=91.8000, 1=95.5000, 2=88.2000, 3=80.5000, 4=94.2000, 5=86.7000, 6=93.2000, 7=92.4000, 8=95.6000, 9=94.6000, 21.8s 36.2m/1.2h
Epoch: [102]
epoch 102/200, train:, losses=0.0593, top1=97.5620, 0=98.1200, 1=99.0400, 2=96.9000, 3=94.9600, 4=97.6000, 5=94.8200, 6=98.5000, 7=98.2400, 8=98.9800, 9=98.4600, eval:, losses=0.2322, top1=91.3700, 0=93.2000, 1=95.6000, 2=88.4000, 3=82.7000, 4=93.1000, 5=83.0000, 6=93.7000, 7=93.7000, 8=96.0000, 9=94.3000, 21.8s 36.6m/1.2h
Epoch: [103]
epoch 103/200, train:, losses=0.0541, top1=97.8840, 0=98.6200, 1=99.0400, 2=97.4400, 3=95.2400, 4=98.0200, 5=95.3200, 6=98.8000, 7=98.6400, 8=99.0600, 9=98.6600, eval:, losses=0.2300, top1=91.6500, 0=91.9000, 1=96.1000, 2=89.7000, 3=85.0000, 4=93.2000, 5=83.5000, 6=93.1000, 7=93.1000, 8=95.8000, 9=95.1000, 20.7s 36.9m/1.2h
Epoch: [104]
epoch 104/200, train:, losses=0.0500, top1=97.8380, 0=98.4000, 1=99.1600, 2=97.0000, 3=95.7000, 4=97.9000, 5=95.7600, 6=98.7800, 7=98.2200, 8=99.0000, 9=98.4600, eval:, losses=0.2320, top1=91.9400, 0=93.5000, 1=95.8000, 2=89.5000, 3=84.0000, 4=93.3000, 5=84.7000, 6=94.2000, 7=94.0000, 8=95.5000, 9=94.9000, 21.4s 37.3m/1.2h
Epoch: [105]
epoch 105/200, train:, losses=0.0467, top1=98.0100, 0=98.7000, 1=99.0000, 2=97.6200, 3=95.2000, 4=98.3600, 5=95.5800, 6=98.9000, 7=98.8800, 8=98.9600, 9=98.9000, eval:, losses=0.2369, top1=91.5500, 0=92.7000, 1=96.3000, 2=87.0000, 3=80.8000, 4=93.1000, 5=88.4000, 6=93.4000, 7=93.6000, 8=95.4000, 9=94.8000, 22.5s 37.7m/1.2h
Epoch: [106]
epoch 106/200, train:, losses=0.0432, top1=98.1400, 0=98.4600, 1=99.1800, 2=98.0600, 3=95.7800, 4=98.0400, 5=96.0400, 6=99.0000, 7=98.8800, 8=99.1000, 9=98.8600, eval:, losses=0.2400, top1=91.6500, 0=92.9000, 1=96.2000, 2=88.4000, 3=83.9000, 4=92.7000, 5=84.0000, 6=94.9000, 7=93.9000, 8=95.6000, 9=94.0000, 20.7s 38.0m/1.2h
Epoch: [107]
epoch 107/200, train:, losses=0.0405, top1=98.2740, 0=98.7800, 1=99.2000, 2=97.5400, 3=96.4400, 4=98.5200, 5=96.0400, 6=99.2400, 7=98.9600, 8=99.1200, 9=98.9000, eval:, losses=0.2445, top1=91.7700, 0=92.7000, 1=95.7000, 2=88.8000, 3=83.4000, 4=94.2000, 5=85.1000, 6=93.4000, 7=93.9000, 8=95.6000, 9=94.9000, 20.5s 38.4m/1.2h
Epoch: [108]
epoch 108/200, train:, losses=0.0381, top1=98.4080, 0=98.9600, 1=99.3200, 2=97.9800, 3=96.6000, 4=98.4000, 5=96.6800, 6=98.8800, 7=98.9600, 8=99.2800, 9=99.0200, eval:, losses=0.2479, top1=91.7000, 0=93.5000, 1=96.2000, 2=88.3000, 3=79.9000, 4=94.2000, 5=86.8000, 6=94.5000, 7=93.5000, 8=95.1000, 9=95.0000, 22.1s 38.7m/1.2h
Epoch: [109]
epoch 109/200, train:, losses=0.0373, top1=98.3820, 0=98.9800, 1=99.2200, 2=98.1400, 3=96.1000, 4=98.6000, 5=96.6600, 6=98.9200, 7=98.8400, 8=99.2200, 9=99.1400, eval:, losses=0.2486, top1=91.7500, 0=91.3000, 1=96.8000, 2=87.4000, 3=83.6000, 4=93.8000, 5=84.8000, 6=94.4000, 7=94.5000, 8=96.0000, 9=94.9000, 22.2s 39.1m/1.2h
Epoch: [110]
epoch 110/200, train:, losses=0.0357, top1=98.4380, 0=98.7600, 1=99.3400, 2=98.1800, 3=96.2800, 4=98.6400, 5=96.8600, 6=99.1200, 7=99.0800, 8=99.1000, 9=99.0200, eval:, losses=0.2503, top1=91.6500, 0=92.6000, 1=95.7000, 2=89.7000, 3=81.6000, 4=92.7000, 5=86.2000, 6=93.7000, 7=93.7000, 8=95.4000, 9=95.2000, 20.7s 39.4m/1.2h
Epoch: [111]
epoch 111/200, train:, losses=0.0354, top1=98.5020, 0=98.8600, 1=99.3200, 2=98.1800, 3=96.7600, 4=98.4400, 5=96.7800, 6=99.1200, 7=98.7000, 8=99.5000, 9=99.3600, eval:, losses=0.2517, top1=92.0300, 0=93.8000, 1=96.0000, 2=89.4000, 3=83.6000, 4=93.7000, 5=85.8000, 6=94.5000, 7=93.2000, 8=95.4000, 9=94.9000, 20.7s 39.8m/1.2h
Epoch: [112]
epoch 112/200, train:, losses=0.0323, top1=98.5880, 0=99.1000, 1=99.3200, 2=98.4600, 3=97.0200, 4=98.5000, 5=97.0400, 6=99.2200, 7=98.9600, 8=99.2000, 9=99.0600, eval:, losses=0.2519, top1=91.7500, 0=93.0000, 1=96.1000, 2=89.1000, 3=83.0000, 4=93.7000, 5=85.5000, 6=94.2000, 7=93.0000, 8=94.8000, 9=95.1000, 20.5s 40.1m/1.2h
Epoch: [113]
epoch 113/200, train:, losses=0.0301, top1=98.7680, 0=99.1800, 1=99.3400, 2=98.6400, 3=97.5200, 4=99.0200, 5=96.9000, 6=99.3600, 7=99.2200, 8=99.4000, 9=99.1000, eval:, losses=0.2515, top1=91.8200, 0=92.9000, 1=95.2000, 2=89.9000, 3=82.7000, 4=93.4000, 5=85.5000, 6=94.8000, 7=93.5000, 8=95.0000, 9=95.3000, 22.6s 40.5m/1.2h
Epoch: [114]
epoch 114/200, train:, losses=0.0301, top1=98.8280, 0=99.1800, 1=99.5600, 2=98.5800, 3=97.3200, 4=99.1000, 5=97.2600, 6=99.3400, 7=99.1400, 8=99.5400, 9=99.2600, eval:, losses=0.2651, top1=91.5700, 0=94.7000, 1=96.0000, 2=86.7000, 3=81.9000, 4=92.8000, 5=87.1000, 6=95.1000, 7=92.0000, 8=95.0000, 9=94.4000, 21.4s 40.9m/1.2h
Epoch: [115]
epoch 115/200, train:, losses=0.0301, top1=98.7600, 0=99.0400, 1=99.3000, 2=98.9200, 3=96.9600, 4=98.9600, 5=97.5200, 6=99.3400, 7=99.0000, 8=99.4600, 9=99.1000, eval:, losses=0.2625, top1=91.6600, 0=94.6000, 1=96.0000, 2=86.6000, 3=81.1000, 4=93.8000, 5=87.3000, 6=94.4000, 7=93.8000, 8=94.5000, 9=94.5000, 22.1s 41.2m/1.2h
Epoch: [116]
epoch 116/200, train:, losses=0.0272, top1=98.8640, 0=99.1000, 1=99.3600, 2=98.7200, 3=97.4800, 4=98.9000, 5=97.7000, 6=99.3800, 7=99.3000, 8=99.4200, 9=99.2800, eval:, losses=0.2599, top1=91.9300, 0=92.5000, 1=96.4000, 2=88.0000, 3=82.1000, 4=94.0000, 5=87.1000, 6=95.1000, 7=93.9000, 8=95.4000, 9=94.8000, 20.1s 41.6m/1.2h
Epoch: [117]
epoch 117/200, train:, losses=0.0265, top1=98.9040, 0=99.1600, 1=99.5000, 2=98.7600, 3=97.7000, 4=99.0800, 5=97.5800, 6=99.1200, 7=99.2800, 8=99.5600, 9=99.3000, eval:, losses=0.2637, top1=91.8100, 0=93.8000, 1=96.6000, 2=89.6000, 3=81.7000, 4=92.9000, 5=87.0000, 6=93.2000, 7=94.0000, 8=94.8000, 9=94.5000, 20.7s 41.9m/1.2h
Epoch: [118]
epoch 118/200, train:, losses=0.0273, top1=98.9200, 0=99.1400, 1=99.6000, 2=98.6400, 3=97.3400, 4=99.1200, 5=97.8000, 6=99.4200, 7=99.2800, 8=99.5000, 9=99.3600, eval:, losses=0.2670, top1=91.7300, 0=93.0000, 1=96.4000, 2=88.4000, 3=83.5000, 4=92.7000, 5=85.9000, 6=94.0000, 7=93.2000, 8=95.0000, 9=95.2000, 22.1s 42.3m/1.2h
Epoch: [119]
epoch 119/200, train:, losses=0.0241, top1=99.0600, 0=99.3400, 1=99.5800, 2=98.7600, 3=97.8600, 4=99.1800, 5=98.0200, 6=99.4600, 7=99.2800, 8=99.6600, 9=99.4600, eval:, losses=0.2620, top1=91.9700, 0=93.6000, 1=95.9000, 2=89.0000, 3=81.4000, 4=93.0000, 5=87.3000, 6=94.7000, 7=94.4000, 8=95.1000, 9=95.3000, 22.9s 42.7m/1.2h
Epoch: [120]
epoch 120/200, train:, losses=0.0235, top1=99.0860, 0=99.4200, 1=99.7000, 2=98.8600, 3=98.2000, 4=99.0200, 5=97.7000, 6=99.6000, 7=99.4000, 8=99.4400, 9=99.5200, eval:, losses=0.2706, top1=92.0200, 0=93.1000, 1=96.3000, 2=89.8000, 3=82.5000, 4=92.5000, 5=87.1000, 6=95.4000, 7=93.4000, 8=95.2000, 9=94.9000, 21.0s 43.0m/1.2h
Epoch: [121]
epoch 121/200, train:, losses=0.0220, top1=99.1760, 0=99.4000, 1=99.5200, 2=98.9000, 3=98.2200, 4=99.2600, 5=98.4400, 6=99.6400, 7=99.3400, 8=99.6600, 9=99.3800, eval:, losses=0.2775, top1=91.6500, 0=92.9000, 1=96.1000, 2=88.1000, 3=84.9000, 4=93.0000, 5=82.9000, 6=94.2000, 7=94.1000, 8=95.5000, 9=94.8000, 21.5s 43.4m/1.2h
Epoch: [122]
epoch 122/200, train:, losses=0.0227, top1=99.0320, 0=99.3400, 1=99.6000, 2=98.7200, 3=97.7600, 4=99.1600, 5=97.9400, 6=99.4800, 7=99.5000, 8=99.4800, 9=99.3400, eval:, losses=0.2759, top1=91.6800, 0=93.4000, 1=96.5000, 2=89.0000, 3=85.2000, 4=93.6000, 5=82.0000, 6=94.6000, 7=93.2000, 8=94.5000, 9=94.8000, 21.0s 43.7m/1.2h
Epoch: [123]
epoch 123/200, train:, losses=0.0216, top1=99.1580, 0=99.4400, 1=99.6000, 2=98.7600, 3=98.0400, 4=99.3000, 5=98.3400, 6=99.5000, 7=99.3600, 8=99.7000, 9=99.5400, eval:, losses=0.2761, top1=91.8400, 0=93.2000, 1=95.8000, 2=89.6000, 3=82.9000, 4=93.6000, 5=85.6000, 6=94.5000, 7=92.9000, 8=95.1000, 9=95.2000, 20.8s 44.1m/1.2h
Epoch: [124]
epoch 124/200, train:, losses=0.0211, top1=99.1820, 0=99.3800, 1=99.6600, 2=98.9800, 3=98.2400, 4=99.2800, 5=98.0400, 6=99.6400, 7=99.4000, 8=99.7000, 9=99.5000, eval:, losses=0.2834, top1=91.7200, 0=94.8000, 1=96.5000, 2=89.0000, 3=81.0000, 4=93.1000, 5=85.2000, 6=95.3000, 7=92.9000, 8=94.8000, 9=94.6000, 21.4s 44.4m/1.2h
Epoch: [125]
epoch 125/200, train:, losses=0.0206, top1=99.1540, 0=99.3200, 1=99.5600, 2=99.1200, 3=98.1000, 4=99.2600, 5=98.4000, 6=99.4200, 7=99.5200, 8=99.4800, 9=99.3600, eval:, losses=0.2855, top1=91.6900, 0=93.0000, 1=95.9000, 2=88.3000, 3=83.4000, 4=93.8000, 5=85.0000, 6=94.7000, 7=92.4000, 8=95.3000, 9=95.1000, 21.6s 44.8m/1.2h
Epoch: [126]
epoch 126/200, train:, losses=0.0205, top1=99.1860, 0=99.5600, 1=99.6400, 2=98.9800, 3=98.3000, 4=99.4800, 5=98.0400, 6=99.5200, 7=99.3000, 8=99.6600, 9=99.3800, eval:, losses=0.2839, top1=91.6900, 0=93.0000, 1=96.7000, 2=88.4000, 3=81.6000, 4=93.7000, 5=86.5000, 6=94.5000, 7=93.0000, 8=94.9000, 9=94.6000, 20.7s 45.1m/1.2h
Epoch: [127]
epoch 127/200, train:, losses=0.0190, top1=99.2440, 0=99.4800, 1=99.6000, 2=99.3400, 3=98.4800, 4=99.2400, 5=98.3800, 6=99.6200, 7=99.3200, 8=99.5800, 9=99.4000, eval:, losses=0.2876, top1=91.8100, 0=92.3000, 1=95.6000, 2=88.4000, 3=83.4000, 4=93.8000, 5=85.4000, 6=94.7000, 7=93.7000, 8=95.6000, 9=95.2000, 21.9s 45.5m/1.2h
Epoch: [128]
epoch 128/200, train:, losses=0.0198, top1=99.2120, 0=99.3200, 1=99.6800, 2=99.0800, 3=98.4000, 4=99.2800, 5=98.1800, 6=99.5800, 7=99.5600, 8=99.5800, 9=99.4600, eval:, losses=0.2901, top1=91.7300, 0=93.6000, 1=96.5000, 2=89.3000, 3=81.6000, 4=94.1000, 5=86.1000, 6=94.4000, 7=92.7000, 8=95.5000, 9=93.5000, 21.7s 45.9m/1.2h
Epoch: [129]
epoch 129/200, train:, losses=0.0181, top1=99.3140, 0=99.4800, 1=99.6800, 2=99.1000, 3=98.5400, 4=99.2600, 5=98.7800, 6=99.5200, 7=99.5800, 8=99.6200, 9=99.5800, eval:, losses=0.2933, top1=91.5200, 0=93.8000, 1=96.1000, 2=88.1000, 3=85.5000, 4=92.9000, 5=82.4000, 6=94.6000, 7=92.7000, 8=95.4000, 9=93.7000, 20.0s 46.2m/1.2h
Epoch: [130]
epoch 130/200, train:, losses=0.0181, top1=99.3020, 0=99.4200, 1=99.5800, 2=99.4000, 3=98.4800, 4=99.3200, 5=98.6000, 6=99.5600, 7=99.4400, 8=99.5800, 9=99.6400, eval:, losses=0.2886, top1=91.7900, 0=92.6000, 1=95.6000, 2=89.0000, 3=82.2000, 4=92.5000, 5=87.3000, 6=95.4000, 7=93.8000, 8=95.0000, 9=94.5000, 20.7s 46.5m/1.2h
Epoch: [131]
epoch 131/200, train:, losses=0.0187, top1=99.2500, 0=99.4600, 1=99.8200, 2=99.1000, 3=98.2200, 4=99.2200, 5=98.5200, 6=99.5800, 7=99.4400, 8=99.6400, 9=99.5000, eval:, losses=0.2948, top1=91.4800, 0=90.9000, 1=96.2000, 2=87.3000, 3=83.5000, 4=92.7000, 5=86.3000, 6=95.1000, 7=93.1000, 8=95.4000, 9=94.3000, 21.5s 46.9m/1.2h
Epoch: [132]
epoch 132/200, train:, losses=0.0171, top1=99.2880, 0=99.4600, 1=99.7200, 2=99.1800, 3=98.2600, 4=99.3200, 5=98.6400, 6=99.5600, 7=99.5600, 8=99.6200, 9=99.5600, eval:, losses=0.2892, top1=91.7500, 0=92.5000, 1=95.4000, 2=89.3000, 3=83.0000, 4=93.5000, 5=85.7000, 6=94.3000, 7=93.8000, 8=94.6000, 9=95.4000, 21.1s 47.2m/1.2h
Epoch: [133]
epoch 133/200, train:, losses=0.0172, top1=99.3620, 0=99.3200, 1=99.8200, 2=99.1600, 3=98.6400, 4=99.4600, 5=98.8000, 6=99.6400, 7=99.5200, 8=99.7400, 9=99.5200, eval:, losses=0.2976, top1=91.4600, 0=93.5000, 1=96.3000, 2=88.5000, 3=85.2000, 4=93.2000, 5=82.6000, 6=93.3000, 7=93.7000, 8=94.5000, 9=93.8000, 21.3s 47.6m/1.2h
Epoch: [134]
epoch 134/200, train:, losses=0.0174, top1=99.3100, 0=99.3600, 1=99.7000, 2=99.1600, 3=98.6400, 4=99.4800, 5=98.4200, 6=99.4800, 7=99.5400, 8=99.7400, 9=99.5800, eval:, losses=0.2893, top1=91.7800, 0=93.4000, 1=95.8000, 2=88.4000, 3=81.9000, 4=93.6000, 5=86.7000, 6=93.9000, 7=93.5000, 8=95.1000, 9=95.5000, 20.4s 47.9m/1.2h
Epoch: [135]
epoch 135/200, train:, losses=0.0169, top1=99.3200, 0=99.5000, 1=99.6800, 2=99.2400, 3=98.4200, 4=99.3000, 5=98.6800, 6=99.5800, 7=99.5600, 8=99.5800, 9=99.6600, eval:, losses=0.2899, top1=91.8200, 0=93.6000, 1=95.8000, 2=90.3000, 3=82.1000, 4=93.3000, 5=84.5000, 6=94.3000, 7=94.4000, 8=94.8000, 9=95.1000, 21.4s 48.3m/1.2h
Epoch: [136]
epoch 136/200, train:, losses=0.0161, top1=99.3800, 0=99.4200, 1=99.7600, 2=99.2600, 3=98.6200, 4=99.5000, 5=98.6000, 6=99.7400, 7=99.6200, 8=99.7000, 9=99.5800, eval:, losses=0.2896, top1=91.6100, 0=93.2000, 1=96.4000, 2=88.7000, 3=81.0000, 4=94.0000, 5=86.8000, 6=93.5000, 7=93.5000, 8=94.4000, 9=94.6000, 21.2s 48.6m/1.2h
Epoch: [137]
epoch 137/200, train:, losses=0.0160, top1=99.3840, 0=99.6000, 1=99.7200, 2=99.3200, 3=98.4400, 4=99.5200, 5=98.6200, 6=99.7200, 7=99.6200, 8=99.6800, 9=99.6000, eval:, losses=0.2957, top1=91.7100, 0=92.9000, 1=95.5000, 2=89.7000, 3=83.6000, 4=92.5000, 5=84.9000, 6=93.9000, 7=93.7000, 8=95.6000, 9=94.8000, 21.8s 49.0m/1.2h
Epoch: [138]
epoch 138/200, train:, losses=0.0150, top1=99.4580, 0=99.5200, 1=99.8400, 2=99.4000, 3=98.9400, 4=99.4000, 5=98.8400, 6=99.6800, 7=99.6400, 8=99.8000, 9=99.5200, eval:, losses=0.2959, top1=91.9100, 0=93.5000, 1=97.0000, 2=89.9000, 3=83.6000, 4=93.1000, 5=86.1000, 6=93.4000, 7=93.5000, 8=94.8000, 9=94.2000, 20.9s 49.4m/1.2h
Epoch: [139]
epoch 139/200, train:, losses=0.0150, top1=99.4240, 0=99.7200, 1=99.6200, 2=99.3400, 3=98.8200, 4=99.4600, 5=98.7800, 6=99.7800, 7=99.6000, 8=99.6800, 9=99.4400, eval:, losses=0.3101, top1=91.3100, 0=92.5000, 1=94.9000, 2=89.8000, 3=83.4000, 4=92.9000, 5=84.3000, 6=93.3000, 7=91.8000, 8=94.6000, 9=95.6000, 21.1s 49.7m/1.2h
Epoch: [140]
epoch 140/200, train:, losses=0.0142, top1=99.4420, 0=99.5200, 1=99.7000, 2=99.4000, 3=98.8600, 4=99.5600, 5=98.9000, 6=99.6600, 7=99.6400, 8=99.6600, 9=99.5200, eval:, losses=0.3016, top1=91.7100, 0=93.6000, 1=95.4000, 2=89.3000, 3=83.4000, 4=93.6000, 5=85.4000, 6=93.7000, 7=93.1000, 8=95.0000, 9=94.6000, 21.7s 50.1m/1.2h
Epoch: [141]
epoch 141/200, train:, losses=0.0150, top1=99.4180, 0=99.6600, 1=99.8400, 2=99.3000, 3=98.7800, 4=99.5800, 5=98.7200, 6=99.5600, 7=99.4600, 8=99.8000, 9=99.4800, eval:, losses=0.2997, top1=91.6200, 0=93.1000, 1=95.6000, 2=88.9000, 3=79.9000, 4=94.0000, 5=86.2000, 6=94.9000, 7=94.7000, 8=93.8000, 9=95.1000, 21.9s 50.4m/1.2h
Epoch: [142]
epoch 142/200, train:, losses=0.0148, top1=99.3900, 0=99.5200, 1=99.8000, 2=99.2800, 3=98.6400, 4=99.2400, 5=98.9400, 6=99.7200, 7=99.5400, 8=99.5800, 9=99.6400, eval:, losses=0.3033, top1=91.6600, 0=93.8000, 1=95.8000, 2=89.0000, 3=83.5000, 4=94.0000, 5=85.3000, 6=93.3000, 7=92.4000, 8=94.6000, 9=94.9000, 21.5s 50.8m/1.2h
Epoch: [143]
epoch 143/200, train:, losses=0.0141, top1=99.4660, 0=99.4400, 1=99.7800, 2=99.4200, 3=98.9400, 4=99.5400, 5=98.9600, 6=99.5400, 7=99.7000, 8=99.7400, 9=99.6000, eval:, losses=0.3075, top1=91.7200, 0=94.3000, 1=95.4000, 2=88.8000, 3=84.1000, 4=93.6000, 5=84.8000, 6=94.5000, 7=92.5000, 8=93.8000, 9=95.4000, 20.8s 51.1m/1.2h
Epoch: [144]
epoch 144/200, train:, losses=0.0140, top1=99.4620, 0=99.7600, 1=99.6200, 2=99.2400, 3=98.9800, 4=99.5000, 5=98.9600, 6=99.6600, 7=99.5600, 8=99.7200, 9=99.6200, eval:, losses=0.3062, top1=91.6600, 0=93.2000, 1=95.4000, 2=87.3000, 3=83.5000, 4=93.6000, 5=85.5000, 6=95.2000, 7=93.1000, 8=94.6000, 9=95.2000, 20.9s 51.5m/1.2h
Epoch: [145]
epoch 145/200, train:, losses=0.0128, top1=99.5400, 0=99.6400, 1=99.6200, 2=99.3400, 3=99.1200, 4=99.6600, 5=99.2200, 6=99.6200, 7=99.7400, 8=99.7000, 9=99.7400, eval:, losses=0.3050, top1=91.9300, 0=94.6000, 1=96.6000, 2=87.4000, 3=82.7000, 4=93.9000, 5=86.7000, 6=94.2000, 7=92.9000, 8=95.7000, 9=94.6000, 20.5s 51.8m/1.2h
Epoch: [146]
epoch 146/200, train:, losses=0.0130, top1=99.4840, 0=99.5400, 1=99.7800, 2=99.5000, 3=98.9800, 4=99.4800, 5=99.0600, 6=99.6600, 7=99.5000, 8=99.7600, 9=99.5800, eval:, losses=0.3003, top1=91.9500, 0=93.6000, 1=96.6000, 2=87.7000, 3=83.7000, 4=93.6000, 5=85.8000, 6=94.7000, 7=93.5000, 8=95.4000, 9=94.9000, 21.0s 52.2m/1.2h
Epoch: [147]
epoch 147/200, train:, losses=0.0136, top1=99.4660, 0=99.6000, 1=99.7800, 2=99.3600, 3=98.9200, 4=99.2800, 5=99.0600, 6=99.6600, 7=99.6600, 8=99.7000, 9=99.6400, eval:, losses=0.3151, top1=91.6300, 0=92.7000, 1=95.4000, 2=88.0000, 3=82.7000, 4=93.1000, 5=86.0000, 6=95.5000, 7=92.8000, 8=95.3000, 9=94.8000, 21.4s 52.5m/1.2h
Epoch: [148]
epoch 148/200, train:, losses=0.0132, top1=99.5080, 0=99.6200, 1=99.8600, 2=99.4000, 3=98.9600, 4=99.5400, 5=99.0200, 6=99.6400, 7=99.6200, 8=99.8400, 9=99.5800, eval:, losses=0.3118, top1=91.7200, 0=93.7000, 1=96.7000, 2=86.9000, 3=83.0000, 4=92.0000, 5=87.1000, 6=94.0000, 7=94.0000, 8=94.9000, 9=94.9000, 21.8s 52.9m/1.2h
Epoch: [149]
epoch 149/200, train:, losses=0.0127, top1=99.5340, 0=99.7000, 1=99.7800, 2=99.3800, 3=99.0600, 4=99.6200, 5=99.0600, 6=99.7000, 7=99.7000, 8=99.8000, 9=99.5400, eval:, losses=0.3108, top1=91.6700, 0=93.8000, 1=94.7000, 2=87.4000, 3=80.4000, 4=93.6000, 5=86.3000, 6=94.7000, 7=94.6000, 8=95.7000, 9=95.5000, 21.5s 53.3m/1.2h
Epoch: [150]
epoch 150/200, train:, losses=0.0110, top1=99.6220, 0=99.6600, 1=99.8000, 2=99.5000, 3=99.1400, 4=99.5800, 5=99.4200, 6=99.8000, 7=99.7000, 8=99.8200, 9=99.8000, eval:, losses=0.3026, top1=91.9100, 0=93.5000, 1=95.4000, 2=89.3000, 3=82.8000, 4=93.9000, 5=84.7000, 6=95.0000, 7=93.6000, 8=95.7000, 9=95.2000, 20.7s 53.6m/1.2h
Epoch: [151]
epoch 151/200, train:, losses=0.0105, top1=99.6200, 0=99.6000, 1=99.8600, 2=99.5800, 3=99.2800, 4=99.6000, 5=99.2000, 6=99.7200, 7=99.7600, 8=99.9000, 9=99.7000, eval:, losses=0.3004, top1=91.9100, 0=93.3000, 1=96.4000, 2=88.9000, 3=82.2000, 4=93.3000, 5=86.3000, 6=94.5000, 7=94.0000, 8=95.4000, 9=94.8000, 21.8s 54.0m/1.2h
Epoch: [152]
epoch 152/200, train:, losses=0.0096, top1=99.6840, 0=99.8200, 1=99.8000, 2=99.6400, 3=99.4800, 4=99.6800, 5=99.3400, 6=99.8200, 7=99.7000, 8=99.7800, 9=99.7800, eval:, losses=0.3013, top1=91.9300, 0=93.8000, 1=95.8000, 2=88.5000, 3=82.5000, 4=93.2000, 5=86.8000, 6=94.3000, 7=93.5000, 8=96.0000, 9=94.9000, 21.7s 54.3m/1.2h
Epoch: [153]
epoch 153/200, train:, losses=0.0093, top1=99.7200, 0=99.7200, 1=99.8200, 2=99.5800, 3=99.5200, 4=99.7400, 5=99.5400, 6=99.9200, 7=99.7400, 8=99.7800, 9=99.8400, eval:, losses=0.3001, top1=91.8900, 0=93.7000, 1=95.7000, 2=88.1000, 3=83.8000, 4=93.1000, 5=85.5000, 6=94.6000, 7=93.7000, 8=95.7000, 9=95.0000, 20.2s 54.7m/1.2h
Epoch: [154]
epoch 154/200, train:, losses=0.0090, top1=99.7180, 0=99.8000, 1=99.9200, 2=99.7200, 3=99.3000, 4=99.7800, 5=99.4000, 6=99.8200, 7=99.7000, 8=99.9000, 9=99.8400, eval:, losses=0.3026, top1=91.9800, 0=93.8000, 1=95.8000, 2=88.6000, 3=82.9000, 4=93.9000, 5=85.8000, 6=95.2000, 7=93.4000, 8=95.4000, 9=95.0000, 20.8s 55.0m/1.2h
Epoch: [155]
epoch 155/200, train:, losses=0.0093, top1=99.6800, 0=99.7000, 1=99.8000, 2=99.6800, 3=99.4400, 4=99.7000, 5=99.2200, 6=99.9000, 7=99.7800, 8=99.8200, 9=99.7600, eval:, losses=0.3011, top1=91.9200, 0=93.2000, 1=95.3000, 2=88.5000, 3=84.2000, 4=93.4000, 5=85.7000, 6=94.4000, 7=93.4000, 8=96.0000, 9=95.1000, 21.7s 55.4m/1.2h
Epoch: [156]
epoch 156/200, train:, losses=0.0096, top1=99.6960, 0=99.8400, 1=99.9000, 2=99.5800, 3=99.3400, 4=99.7400, 5=99.4000, 6=99.7800, 7=99.8000, 8=99.8600, 9=99.7200, eval:, losses=0.3019, top1=92.0100, 0=93.9000, 1=95.9000, 2=88.7000, 3=84.1000, 4=93.4000, 5=85.7000, 6=94.2000, 7=93.6000, 8=95.7000, 9=94.9000, 22.1s 55.7m/1.2h
Epoch: [157]
epoch 157/200, train:, losses=0.0086, top1=99.7240, 0=99.8200, 1=99.8200, 2=99.5600, 3=99.5000, 4=99.9000, 5=99.4800, 6=99.8400, 7=99.6800, 8=99.8200, 9=99.8200, eval:, losses=0.3005, top1=91.9500, 0=93.4000, 1=95.5000, 2=90.1000, 3=83.4000, 4=93.5000, 5=85.9000, 6=94.1000, 7=93.3000, 8=95.1000, 9=95.2000, 20.8s 56.1m/1.2h
Epoch: [158]
epoch 158/200, train:, losses=0.0084, top1=99.7140, 0=99.7200, 1=99.9200, 2=99.5800, 3=99.4200, 4=99.7200, 5=99.4600, 6=99.8000, 7=99.7800, 8=99.9400, 9=99.8000, eval:, losses=0.3007, top1=91.7300, 0=93.3000, 1=95.1000, 2=88.1000, 3=82.7000, 4=93.5000, 5=86.5000, 6=94.2000, 7=93.3000, 8=95.1000, 9=95.5000, 20.9s 56.4m/1.2h
Epoch: [159]
epoch 159/200, train:, losses=0.0083, top1=99.7480, 0=99.7800, 1=99.8600, 2=99.7600, 3=99.3800, 4=99.7200, 5=99.5000, 6=99.9000, 7=99.7800, 8=99.9000, 9=99.9000, eval:, losses=0.3024, top1=91.9500, 0=93.4000, 1=95.8000, 2=89.1000, 3=83.9000, 4=93.5000, 5=86.1000, 6=94.5000, 7=93.2000, 8=95.5000, 9=94.5000, 20.4s 56.8m/1.2h
Epoch: [160]
epoch 160/200, train:, losses=0.0084, top1=99.7540, 0=99.8800, 1=99.9000, 2=99.6200, 3=99.5800, 4=99.8400, 5=99.5800, 6=99.7800, 7=99.7400, 8=99.8600, 9=99.7600, eval:, losses=0.3027, top1=91.9700, 0=93.7000, 1=95.9000, 2=89.4000, 3=83.5000, 4=94.0000, 5=85.5000, 6=94.3000, 7=93.5000, 8=95.5000, 9=94.4000, 21.9s 57.1m/1.2h
Epoch: [161]
epoch 161/200, train:, losses=0.0090, top1=99.6980, 0=99.6600, 1=99.8800, 2=99.7000, 3=99.4800, 4=99.7400, 5=99.4200, 6=99.8400, 7=99.7200, 8=99.8000, 9=99.7400, eval:, losses=0.3035, top1=91.7400, 0=93.3000, 1=95.0000, 2=88.3000, 3=82.3000, 4=93.7000, 5=85.2000, 6=94.4000, 7=94.3000, 8=95.4000, 9=95.5000, 21.1s 57.5m/1.2h
Epoch: [162]
epoch 162/200, train:, losses=0.0083, top1=99.7540, 0=99.8200, 1=99.9200, 2=99.7400, 3=99.4800, 4=99.7800, 5=99.3600, 6=99.8400, 7=99.8800, 8=99.8400, 9=99.8800, eval:, losses=0.3024, top1=91.8800, 0=93.5000, 1=94.7000, 2=89.2000, 3=83.1000, 4=93.2000, 5=85.8000, 6=95.1000, 7=93.4000, 8=95.6000, 9=95.2000, 21.5s 57.9m/1.2h
Epoch: [163]
epoch 163/200, train:, losses=0.0078, top1=99.7500, 0=99.7000, 1=99.8600, 2=99.6200, 3=99.5600, 4=99.7800, 5=99.5600, 6=99.8800, 7=99.9000, 8=99.9000, 9=99.7400, eval:, losses=0.3010, top1=91.9600, 0=93.2000, 1=96.0000, 2=88.7000, 3=83.1000, 4=93.1000, 5=86.4000, 6=95.4000, 7=93.4000, 8=95.4000, 9=94.9000, 21.7s 58.2m/1.2h
Epoch: [164]
epoch 164/200, train:, losses=0.0083, top1=99.7480, 0=99.8200, 1=99.9000, 2=99.7400, 3=99.4000, 4=99.8200, 5=99.4800, 6=99.8400, 7=99.8000, 8=99.8600, 9=99.8200, eval:, losses=0.2986, top1=92.1000, 0=93.9000, 1=95.9000, 2=88.8000, 3=84.2000, 4=93.2000, 5=86.0000, 6=95.4000, 7=93.4000, 8=95.6000, 9=94.6000, 21.3s 58.6m/1.2h
Epoch: [165]
epoch 165/200, train:, losses=0.0088, top1=99.7160, 0=99.8600, 1=99.7400, 2=99.6600, 3=99.4400, 4=99.6400, 5=99.4600, 6=99.8600, 7=99.8000, 8=99.8600, 9=99.8400, eval:, losses=0.3013, top1=91.8900, 0=93.7000, 1=95.5000, 2=89.5000, 3=82.7000, 4=93.3000, 5=85.7000, 6=94.2000, 7=93.6000, 8=95.7000, 9=95.0000, 21.8s 58.9m/1.2h
Epoch: [166]
epoch 166/200, train:, losses=0.0079, top1=99.7520, 0=99.8200, 1=99.9000, 2=99.6000, 3=99.5000, 4=99.8000, 5=99.3800, 6=99.9000, 7=99.9200, 8=99.8800, 9=99.8200, eval:, losses=0.3030, top1=91.9500, 0=93.1000, 1=95.4000, 2=89.1000, 3=82.2000, 4=93.6000, 5=86.7000, 6=95.0000, 7=93.1000, 8=96.1000, 9=95.2000, 23.5s 59.3m/1.2h
Epoch: [167]
epoch 167/200, train:, losses=0.0082, top1=99.7460, 0=99.8600, 1=99.8400, 2=99.6600, 3=99.5800, 4=99.7600, 5=99.4400, 6=99.9000, 7=99.7800, 8=99.8400, 9=99.8000, eval:, losses=0.3016, top1=91.8500, 0=92.8000, 1=95.9000, 2=89.0000, 3=80.9000, 4=93.7000, 5=86.5000, 6=94.8000, 7=93.8000, 8=95.7000, 9=95.4000, 21.0s 59.7m/1.2h
Epoch: [168]
epoch 168/200, train:, losses=0.0074, top1=99.7680, 0=99.8200, 1=99.8400, 2=99.7400, 3=99.7200, 4=99.7600, 5=99.3600, 6=99.9200, 7=99.9000, 8=99.7600, 9=99.8600, eval:, losses=0.3022, top1=91.9200, 0=93.7000, 1=96.0000, 2=88.5000, 3=81.9000, 4=93.1000, 5=86.2000, 6=95.4000, 7=93.8000, 8=95.8000, 9=94.8000, 20.6s 1.0h/1.2h
Epoch: [169]
epoch 169/200, train:, losses=0.0073, top1=99.7960, 0=99.8000, 1=99.9200, 2=99.7400, 3=99.5200, 4=99.9200, 5=99.6400, 6=99.8800, 7=99.8200, 8=99.9200, 9=99.8000, eval:, losses=0.3001, top1=91.9700, 0=93.4000, 1=95.8000, 2=89.1000, 3=82.6000, 4=93.3000, 5=86.6000, 6=94.7000, 7=93.6000, 8=95.5000, 9=95.1000, 20.3s 1.0h/1.2h
Epoch: [170]
epoch 170/200, train:, losses=0.0076, top1=99.7760, 0=99.8400, 1=99.9000, 2=99.6600, 3=99.6000, 4=99.8600, 5=99.5400, 6=99.8800, 7=99.7600, 8=99.9000, 9=99.8200, eval:, losses=0.3014, top1=92.0000, 0=93.2000, 1=95.2000, 2=89.0000, 3=83.8000, 4=94.0000, 5=86.0000, 6=94.4000, 7=93.7000, 8=95.5000, 9=95.2000, 20.8s 1.0h/1.2h
Epoch: [171]
epoch 171/200, train:, losses=0.0081, top1=99.7360, 0=99.7800, 1=99.9000, 2=99.7400, 3=99.4600, 4=99.7000, 5=99.4600, 6=99.8400, 7=99.7600, 8=99.9200, 9=99.8000, eval:, losses=0.3021, top1=92.0600, 0=93.4000, 1=95.9000, 2=88.9000, 3=83.4000, 4=93.8000, 5=85.5000, 6=95.4000, 7=93.6000, 8=95.3000, 9=95.4000, 21.2s 1.0h/1.2h
Epoch: [172]
epoch 172/200, train:, losses=0.0078, top1=99.7500, 0=99.8400, 1=99.8800, 2=99.7800, 3=99.4000, 4=99.6800, 5=99.5600, 6=99.8600, 7=99.8000, 8=99.8600, 9=99.8400, eval:, losses=0.3031, top1=92.0600, 0=93.6000, 1=95.8000, 2=89.8000, 3=83.7000, 4=93.5000, 5=85.7000, 6=94.7000, 7=93.8000, 8=94.7000, 9=95.3000, 22.4s 1.0h/1.2h
Epoch: [173]
epoch 173/200, train:, losses=0.0081, top1=99.7520, 0=99.7600, 1=99.8600, 2=99.7600, 3=99.4800, 4=99.7800, 5=99.6200, 6=99.8000, 7=99.8400, 8=99.9000, 9=99.7200, eval:, losses=0.3010, top1=92.0000, 0=93.5000, 1=96.0000, 2=89.2000, 3=83.0000, 4=93.6000, 5=86.0000, 6=94.8000, 7=94.1000, 8=94.6000, 9=95.2000, 21.4s 1.0h/1.2h
Epoch: [174]
epoch 174/200, train:, losses=0.0074, top1=99.8100, 0=99.8800, 1=99.9200, 2=99.8200, 3=99.6800, 4=99.8200, 5=99.6000, 6=99.9200, 7=99.7400, 8=99.9200, 9=99.8000, eval:, losses=0.2998, top1=92.0000, 0=93.5000, 1=95.9000, 2=89.5000, 3=83.0000, 4=93.3000, 5=85.8000, 6=95.1000, 7=93.5000, 8=95.4000, 9=95.0000, 21.0s 1.0h/1.2h
Epoch: [175]
epoch 175/200, train:, losses=0.0073, top1=99.7920, 0=99.8600, 1=99.8800, 2=99.8000, 3=99.6000, 4=99.7400, 5=99.5000, 6=99.8400, 7=99.8400, 8=99.9400, 9=99.9200, eval:, losses=0.3037, top1=91.8800, 0=93.2000, 1=95.8000, 2=89.4000, 3=82.5000, 4=93.5000, 5=85.5000, 6=94.6000, 7=94.0000, 8=95.0000, 9=95.3000, 22.8s 1.0h/1.2h
Epoch: [176]
epoch 176/200, train:, losses=0.0076, top1=99.7620, 0=99.8600, 1=99.9000, 2=99.7800, 3=99.4400, 4=99.8000, 5=99.5400, 6=99.8800, 7=99.8000, 8=99.8000, 9=99.8200, eval:, losses=0.3005, top1=92.0900, 0=93.4000, 1=95.9000, 2=89.4000, 3=83.0000, 4=93.1000, 5=86.1000, 6=95.4000, 7=94.1000, 8=95.7000, 9=94.8000, 20.6s 1.0h/1.2h
Epoch: [177]
epoch 177/200, train:, losses=0.0071, top1=99.8040, 0=99.9200, 1=99.9000, 2=99.8000, 3=99.6400, 4=99.8000, 5=99.4600, 6=99.9600, 7=99.8400, 8=99.8400, 9=99.8800, eval:, losses=0.3011, top1=92.1600, 0=94.0000, 1=96.4000, 2=89.8000, 3=82.6000, 4=93.4000, 5=86.2000, 6=95.0000, 7=94.0000, 8=95.2000, 9=95.0000, 20.5s 1.1h/1.2h
Epoch: [178]
epoch 178/200, train:, losses=0.0075, top1=99.7640, 0=99.8200, 1=99.8400, 2=99.6800, 3=99.5400, 4=99.8600, 5=99.5400, 6=99.8800, 7=99.8200, 8=99.8400, 9=99.8200, eval:, losses=0.3022, top1=91.9600, 0=93.6000, 1=96.2000, 2=88.2000, 3=82.6000, 4=93.4000, 5=86.6000, 6=94.3000, 7=93.9000, 8=95.5000, 9=95.3000, 21.3s 1.1h/1.2h
Epoch: [179]
epoch 179/200, train:, losses=0.0075, top1=99.7820, 0=99.7800, 1=99.9400, 2=99.6400, 3=99.6400, 4=99.8600, 5=99.4600, 6=99.9400, 7=99.9000, 8=99.8600, 9=99.8000, eval:, losses=0.3016, top1=92.0200, 0=93.2000, 1=95.4000, 2=90.4000, 3=83.2000, 4=92.8000, 5=86.8000, 6=94.6000, 7=93.6000, 8=95.1000, 9=95.1000, 21.0s 1.1h/1.2h
Epoch: [180]
epoch 180/200, train:, losses=0.0077, top1=99.7660, 0=99.7000, 1=99.9000, 2=99.7600, 3=99.5400, 4=99.8400, 5=99.6000, 6=99.8000, 7=99.9600, 8=99.8200, 9=99.7400, eval:, losses=0.3022, top1=91.8200, 0=93.4000, 1=95.5000, 2=89.3000, 3=81.9000, 4=93.7000, 5=86.2000, 6=94.4000, 7=93.9000, 8=94.9000, 9=95.0000, 20.7s 1.1h/1.2h
Epoch: [181]
epoch 181/200, train:, losses=0.0068, top1=99.8220, 0=99.8000, 1=99.9600, 2=99.7400, 3=99.6000, 4=99.7800, 5=99.7800, 6=99.8800, 7=99.9000, 8=99.9600, 9=99.8200, eval:, losses=0.2992, top1=92.1700, 0=93.0000, 1=96.0000, 2=89.2000, 3=83.7000, 4=93.7000, 5=85.9000, 6=95.2000, 7=94.2000, 8=95.6000, 9=95.2000, 21.4s 1.1h/1.2h
Epoch: [182]
epoch 182/200, train:, losses=0.0071, top1=99.7720, 0=99.7400, 1=99.8400, 2=99.5400, 3=99.6000, 4=99.8200, 5=99.6400, 6=99.9000, 7=99.8600, 8=99.9200, 9=99.8600, eval:, losses=0.3046, top1=92.1700, 0=93.9000, 1=95.5000, 2=90.1000, 3=83.6000, 4=93.8000, 5=86.1000, 6=95.0000, 7=93.3000, 8=95.6000, 9=94.8000, 21.5s 1.1h/1.2h
Epoch: [183]
epoch 183/200, train:, losses=0.0077, top1=99.7660, 0=99.8200, 1=99.7800, 2=99.6200, 3=99.6000, 4=99.8000, 5=99.6400, 6=99.8400, 7=99.8600, 8=99.9200, 9=99.7800, eval:, losses=0.3028, top1=92.2200, 0=93.8000, 1=96.3000, 2=89.7000, 3=84.2000, 4=94.0000, 5=84.9000, 6=95.1000, 7=93.5000, 8=95.5000, 9=95.2000, 20.3s 1.1h/1.2h
Epoch: [184]
epoch 184/200, train:, losses=0.0074, top1=99.7880, 0=99.8400, 1=99.8800, 2=99.8000, 3=99.6600, 4=99.6800, 5=99.6000, 6=99.8600, 7=99.8000, 8=99.9600, 9=99.8000, eval:, losses=0.3055, top1=91.9800, 0=94.1000, 1=95.2000, 2=88.0000, 3=83.3000, 4=93.9000, 5=87.1000, 6=94.3000, 7=93.5000, 8=95.2000, 9=95.2000, 21.0s 1.1h/1.2h
Epoch: [185]
epoch 185/200, train:, losses=0.0071, top1=99.8100, 0=99.8400, 1=99.8800, 2=99.7200, 3=99.6800, 4=99.7600, 5=99.6800, 6=99.9000, 7=99.8200, 8=99.9400, 9=99.8800, eval:, losses=0.3038, top1=92.1000, 0=93.4000, 1=95.7000, 2=89.5000, 3=84.1000, 4=93.9000, 5=85.2000, 6=95.3000, 7=93.5000, 8=95.5000, 9=94.9000, 22.3s 1.1h/1.2h
Epoch: [186]
epoch 186/200, train:, losses=0.0072, top1=99.7740, 0=99.8000, 1=99.9200, 2=99.8800, 3=99.5200, 4=99.8200, 5=99.4600, 6=99.8800, 7=99.7800, 8=99.8800, 9=99.8000, eval:, losses=0.3056, top1=91.9800, 0=94.2000, 1=95.4000, 2=88.2000, 3=83.9000, 4=94.1000, 5=85.6000, 6=95.2000, 7=93.4000, 8=94.7000, 9=95.1000, 21.3s 1.1h/1.2h
Epoch: [187]
epoch 187/200, train:, losses=0.0072, top1=99.7780, 0=99.7600, 1=99.8000, 2=99.7800, 3=99.6200, 4=99.8400, 5=99.5200, 6=99.9400, 7=99.7800, 8=99.9200, 9=99.8200, eval:, losses=0.3041, top1=92.0200, 0=93.2000, 1=95.5000, 2=89.4000, 3=82.3000, 4=93.7000, 5=86.8000, 6=95.2000, 7=93.2000, 8=95.8000, 9=95.1000, 21.5s 1.1h/1.2h
Epoch: [188]
epoch 188/200, train:, losses=0.0069, top1=99.8120, 0=99.7800, 1=99.9000, 2=99.7600, 3=99.8800, 4=99.8600, 5=99.6200, 6=99.8800, 7=99.8600, 8=99.8400, 9=99.7400, eval:, losses=0.3061, top1=92.0000, 0=93.6000, 1=95.7000, 2=89.2000, 3=82.6000, 4=93.9000, 5=86.6000, 6=94.9000, 7=93.2000, 8=95.5000, 9=94.8000, 20.8s 1.1h/1.2h
Epoch: [189]
epoch 189/200, train:, losses=0.0074, top1=99.7720, 0=99.8600, 1=99.8600, 2=99.8000, 3=99.4200, 4=99.7400, 5=99.5800, 6=99.8600, 7=99.9000, 8=99.8800, 9=99.8200, eval:, losses=0.3045, top1=92.1100, 0=94.3000, 1=96.1000, 2=88.2000, 3=83.8000, 4=94.1000, 5=85.4000, 6=95.0000, 7=93.6000, 8=95.6000, 9=95.0000, 21.6s 1.1h/1.2h
Epoch: [190]
epoch 190/200, train:, losses=0.0070, top1=99.7860, 0=99.8600, 1=99.8800, 2=99.7000, 3=99.6600, 4=99.8000, 5=99.6200, 6=99.9000, 7=99.8600, 8=99.7600, 9=99.8200, eval:, losses=0.3043, top1=92.2100, 0=93.7000, 1=96.5000, 2=89.4000, 3=83.2000, 4=93.8000, 5=86.5000, 6=95.4000, 7=94.1000, 8=94.6000, 9=94.9000, 21.2s 1.1h/1.2h
Epoch: [191]
epoch 191/200, train:, losses=0.0065, top1=99.8160, 0=99.8400, 1=99.9200, 2=99.8200, 3=99.6800, 4=99.7600, 5=99.6400, 6=99.8000, 7=99.9000, 8=99.9200, 9=99.8800, eval:, losses=0.3019, top1=92.1900, 0=93.0000, 1=96.2000, 2=89.8000, 3=83.0000, 4=93.5000, 5=86.8000, 6=95.1000, 7=93.8000, 8=96.1000, 9=94.6000, 21.0s 1.1h/1.2h
Epoch: [192]
epoch 192/200, train:, losses=0.0071, top1=99.7980, 0=99.7600, 1=99.9400, 2=99.7200, 3=99.7200, 4=99.7600, 5=99.6200, 6=99.8200, 7=99.8400, 8=99.8800, 9=99.9200, eval:, losses=0.3034, top1=92.0900, 0=93.4000, 1=95.9000, 2=89.6000, 3=84.9000, 4=93.7000, 5=85.2000, 6=94.3000, 7=93.6000, 8=95.1000, 9=95.2000, 20.8s 1.1h/1.2h
Epoch: [193]
epoch 193/200, train:, losses=0.0075, top1=99.7800, 0=99.8600, 1=99.8600, 2=99.7400, 3=99.6600, 4=99.7800, 5=99.6200, 6=99.9200, 7=99.7200, 8=99.8600, 9=99.7800, eval:, losses=0.3027, top1=92.1900, 0=93.8000, 1=96.1000, 2=89.6000, 3=83.5000, 4=93.8000, 5=86.5000, 6=94.9000, 7=93.3000, 8=95.5000, 9=94.9000, 21.1s 1.1h/1.2h
Epoch: [194]
epoch 194/200, train:, losses=0.0069, top1=99.8100, 0=99.9200, 1=99.9400, 2=99.7400, 3=99.6600, 4=99.8200, 5=99.6400, 6=99.8400, 7=99.8200, 8=99.9200, 9=99.8000, eval:, losses=0.3052, top1=92.0900, 0=93.9000, 1=96.2000, 2=89.8000, 3=82.0000, 4=93.4000, 5=85.9000, 6=95.1000, 7=94.2000, 8=95.2000, 9=95.2000, 21.6s 1.2h/1.2h
Epoch: [195]
epoch 195/200, train:, losses=0.0069, top1=99.8000, 0=99.8200, 1=99.9200, 2=99.7000, 3=99.5800, 4=99.8400, 5=99.6200, 6=99.9000, 7=99.8800, 8=99.9200, 9=99.8200, eval:, losses=0.3060, top1=92.1000, 0=93.8000, 1=95.8000, 2=90.1000, 3=82.1000, 4=93.9000, 5=86.0000, 6=95.0000, 7=94.1000, 8=95.6000, 9=94.6000, 21.7s 1.2h/1.2h
Epoch: [196]
epoch 196/200, train:, losses=0.0069, top1=99.8080, 0=99.7800, 1=99.9200, 2=99.8000, 3=99.4400, 4=99.8600, 5=99.7800, 6=99.9600, 7=99.8000, 8=99.8800, 9=99.8600, eval:, losses=0.3024, top1=92.1600, 0=94.0000, 1=95.8000, 2=89.3000, 3=83.2000, 4=93.3000, 5=86.4000, 6=95.2000, 7=94.0000, 8=95.6000, 9=94.8000, 21.0s 1.2h/1.2h
Epoch: [197]
epoch 197/200, train:, losses=0.0071, top1=99.8140, 0=99.7800, 1=99.8000, 2=99.8000, 3=99.7000, 4=99.9400, 5=99.6400, 6=99.8400, 7=99.9200, 8=99.9200, 9=99.8000, eval:, losses=0.3051, top1=92.1700, 0=94.2000, 1=95.8000, 2=89.5000, 3=83.4000, 4=93.6000, 5=86.2000, 6=95.4000, 7=93.7000, 8=95.4000, 9=94.5000, 22.5s 1.2h/1.2h
Epoch: [198]
epoch 198/200, train:, losses=0.0067, top1=99.8280, 0=99.9400, 1=99.8200, 2=99.8400, 3=99.6800, 4=99.9200, 5=99.6400, 6=99.8400, 7=99.9000, 8=99.9000, 9=99.8000, eval:, losses=0.3061, top1=92.1300, 0=93.6000, 1=95.9000, 2=89.6000, 3=83.2000, 4=93.8000, 5=86.2000, 6=95.1000, 7=93.8000, 8=95.5000, 9=94.6000, 21.2s 1.2h/1.2h
Epoch: [199]
epoch 199/200, train:, losses=0.0065, top1=99.8280, 0=99.8800, 1=99.9400, 2=99.8200, 3=99.6600, 4=99.7400, 5=99.7200, 6=99.9000, 7=99.9000, 8=99.9200, 9=99.8000, eval:, losses=0.3030, top1=92.1700, 0=92.8000, 1=96.1000, 2=89.8000, 3=84.6000, 4=93.9000, 5=85.1000, 6=94.9000, 7=93.8000, 8=95.7000, 9=95.0000, 21.6s 1.2h/1.2h
Epoch: [200]
epoch 200/200, train:, losses=0.0068, top1=99.7980, 0=99.9200, 1=99.9800, 2=99.7400, 3=99.7400, 4=99.8000, 5=99.5200, 6=99.9000, 7=99.7400, 8=99.8800, 9=99.7600, eval:, losses=0.3072, top1=92.0700, 0=93.6000, 1=95.5000, 2=89.1000, 3=82.9000, 4=93.8000, 5=86.6000, 6=95.6000, 7=93.3000, 8=95.2000, 9=95.1000, 21.1s 1.2h/1.2h
